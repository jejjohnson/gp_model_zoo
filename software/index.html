


<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Python Packages for GPs">
      
      
        <link rel="canonical" href="https://jejjohnson.github.io/gp_model_zoo/software/">
      
      
        <meta name="author" content="J. Emmanuel Johnson">
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-5.1.3">
    
    
      
        <title>Software</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.62d34fff.min.css">
      
        <link rel="stylesheet" href="../assets/stylesheets/palette.c8acc6db.min.css">
      
      
        
        
        <meta name="theme-color" content="#ef5350">
      
    
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=source+code+pro:300,400,400i,700%7Csource+code+pro&display=fallback">
        <style>body,input{font-family:"source code pro",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"source code pro",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
      <link rel="stylesheet" href="../css/ansi-colours.css">
    
      <link rel="stylesheet" href="../css/jupyter-cells.css">
    
      <link rel="stylesheet" href="../css/pandas-dataframe.css">
    
    
      
    
    
  </head>
  
  
    
    
    <body dir="ltr" data-md-color-primary="red" data-md-color-accent="black">
  
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#software" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href="https://jejjohnson.github.io/gp_model_zoo" title="GP Model Zoo" class="md-header-nav__button md-logo" aria-label="GP Model Zoo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12,8A3,3 0 0,0 15,5A3,3 0 0,0 12,2A3,3 0 0,0 9,5A3,3 0 0,0 12,8M12,11.54C9.64,9.35 6.5,8 3,8V19C6.5,19 9.64,20.35 12,22.54C14.36,20.35 17.5,19 21,19V8C17.5,8 14.36,9.35 12,11.54Z" /></svg>

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3,6H21V8H3V6M3,11H21V13H3V11M3,16H21V18H3V16Z" /></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      
        <div class="md-header-nav__ellipsis">
          <span class="md-header-nav__topic md-ellipsis">
            GP Model Zoo
          </span>
          <span class="md-header-nav__topic md-ellipsis">
            
              Software
            
          </span>
        </div>
      
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5,3A6.5,6.5 0 0,1 16,9.5C16,11.11 15.41,12.59 14.44,13.73L14.71,14H15.5L20.5,19L19,20.5L14,15.5V14.71L13.73,14.44C12.59,15.41 11.11,16 9.5,16A6.5,6.5 0 0,1 3,9.5A6.5,6.5 0 0,1 9.5,3M9.5,5C7,5 5,7 5,9.5C5,12 7,14 9.5,14C12,14 14,12 14,9.5C14,7 12,5 9.5,5Z" /></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active">
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5,3A6.5,6.5 0 0,1 16,9.5C16,11.11 15.41,12.59 14.44,13.73L14.71,14H15.5L20.5,19L19,20.5L14,15.5V14.71L13.73,14.44C12.59,15.41 11.11,16 9.5,16A6.5,6.5 0 0,1 3,9.5A6.5,6.5 0 0,1 9.5,3M9.5,5C7,5 5,7 5,9.5C5,12 7,14 9.5,14C12,14 14,12 14,9.5C14,7 12,5 9.5,5Z" /></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20,11V13H8L13.5,18.5L12.08,19.92L4.16,12L12.08,4.08L13.5,5.5L8,11H20Z" /></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19,6.41L17.59,5L12,10.59L6.41,5L5,6.41L10.59,12L5,17.59L6.41,19L12,13.41L17.59,19L19,17.59L13.41,12L19,6.41Z" /></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header-nav__source">
        
<a href="https://github.com/jejjohnson/gp_model_zoo/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    jejjohnson/gp_model_zoo
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
        
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="https://jejjohnson.github.io/gp_model_zoo" title="GP Model Zoo" class="md-nav__button md-logo" aria-label="GP Model Zoo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12,8A3,3 0 0,0 15,5A3,3 0 0,0 12,2A3,3 0 0,0 9,5A3,3 0 0,0 12,8M12,11.54C9.64,9.35 6.5,8 3,8V19C6.5,19 9.64,20.35 12,22.54C14.36,20.35 17.5,19 21,19V8C17.5,8 14.36,9.35 12,11.54Z" /></svg>

    </a>
    GP Model Zoo
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/jejjohnson/gp_model_zoo/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    jejjohnson/gp_model_zoo
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." title="Home" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Software
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3,9H17V7H3V9M3,13H17V11H3V13M3,17H17V15H3V17M19,17H21V15H19V17M19,7V9H21V7H19M19,13H21V11H19V13Z" /></svg>
        </span>
      </label>
    
    <a href="./" title="Software" class="md-nav__link md-nav__link--active">
      Software
    </a>
    
      
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20,11V13H8L13.5,18.5L12.08,19.92L4.16,12L12.08,4.08L13.5,5.5L8,11H20Z" /></svg>
      </span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#what-is-deep-learning" class="md-nav__link">
    What is Deep Learning?
  </a>
  
    <nav class="md-nav" aria-label="What is Deep Learning?">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#anatomy-of-good-dl-software" class="md-nav__link">
    Anatomy of good DL software
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#convergence-of-the-libraries" class="md-nav__link">
    Convergence of the Libraries
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#python-packages" class="md-nav__link">
    Python Packages
  </a>
  
    <nav class="md-nav" aria-label="Python Packages">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tldr-my-recommendations" class="md-nav__link">
    TLDR - My Recommendations
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scikit-learn" class="md-nav__link">
    scikit-learn
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpy" class="md-nav__link">
    GPy
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpytorch" class="md-nav__link">
    GPyTorch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpflow" class="md-nav__link">
    GPFlow
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#other-libraries" class="md-nav__link">
    Other Libraries
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gpu-support" class="md-nav__link">
    GPU Support
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#algorithms-implemented" class="md-nav__link">
    Algorithms Implemented
  </a>
  
</li>
      
    </ul>
  
</nav>
    
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../intro/" title="Intro to GPs" class="md-nav__link">
      Intro to GPs
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4">
    
    <label class="md-nav__link" for="nav-4">
      Literature
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59,16.58L13.17,12L8.59,7.41L10,6L16,12L10,18L8.59,16.58Z" /></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="Literature" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20,11V13H8L13.5,18.5L12.08,19.92L4.16,12L12.08,4.08L13.5,5.5L8,11H20Z" /></svg>
        </span>
        Literature
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../literature/" title="About" class="md-nav__link">
      About
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../literature/kernels/" title="Kernels" class="md-nav__link">
      Kernels
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../literature/sparse_gps/" title="Sparse GPs" class="md-nav__link">
      Sparse GPs
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../literature/inference/" title="Inference" class="md-nav__link">
      Inference
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../literature/large_scale/" title="Large Scale" class="md-nav__link">
      Large Scale
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../literature/fourier/" title="Fourier" class="md-nav__link">
      Fourier
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../literature/deep_gps/" title="Deep GPs" class="md-nav__link">
      Deep GPs
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../literature/multioutput/" title="Multi-Output" class="md-nav__link">
      Multi-Output
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../literature/state_space/" title="State-Space" class="md-nav__link">
      State-Space
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../literature/uncertain_inputs/" title="Uncertain Inputs" class="md-nav__link">
      Uncertain Inputs
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4-11" type="checkbox" id="nav-4-11">
    
    <label class="md-nav__link" for="nav-4-11">
      Applications
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59,16.58L13.17,12L8.59,7.41L10,6L16,12L10,18L8.59,16.58Z" /></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="Applications" data-md-level="2">
      <label class="md-nav__title" for="nav-4-11">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20,11V13H8L13.5,18.5L12.08,19.92L4.16,12L12.08,4.08L13.5,5.5L8,11H20Z" /></svg>
        </span>
        Applications
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../literature/applications/overview/" title="Overview" class="md-nav__link">
      Overview
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../literature/applications/emulation/" title="Emulation" class="md-nav__link">
      Emulation
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../literature/applications/bayes_opt/" title="Bayesian Opt." class="md-nav__link">
      Bayesian Opt.
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5">
    
    <label class="md-nav__link" for="nav-5">
      Demos
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59,16.58L13.17,12L8.59,7.41L10,6L16,12L10,18L8.59,16.58Z" /></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="Demos" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20,11V13H8L13.5,18.5L12.08,19.92L4.16,12L12.08,4.08L13.5,5.5L8,11H20Z" /></svg>
        </span>
        Demos
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../demos/" title="Overview" class="md-nav__link">
      Overview
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../demos/1d_example/" title="1D Example" class="md-nav__link">
      1D Example
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../demos/1d_example_ls/" title="1D Example (Large Scale)" class="md-nav__link">
      1D Example (Large Scale)
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20,11V13H8L13.5,18.5L12.08,19.92L4.16,12L12.08,4.08L13.5,5.5L8,11H20Z" /></svg>
      </span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#what-is-deep-learning" class="md-nav__link">
    What is Deep Learning?
  </a>
  
    <nav class="md-nav" aria-label="What is Deep Learning?">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#anatomy-of-good-dl-software" class="md-nav__link">
    Anatomy of good DL software
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#convergence-of-the-libraries" class="md-nav__link">
    Convergence of the Libraries
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#python-packages" class="md-nav__link">
    Python Packages
  </a>
  
    <nav class="md-nav" aria-label="Python Packages">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tldr-my-recommendations" class="md-nav__link">
    TLDR - My Recommendations
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scikit-learn" class="md-nav__link">
    scikit-learn
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpy" class="md-nav__link">
    GPy
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpytorch" class="md-nav__link">
    GPyTorch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpflow" class="md-nav__link">
    GPFlow
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#other-libraries" class="md-nav__link">
    Other Libraries
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gpu-support" class="md-nav__link">
    GPU Support
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#algorithms-implemented" class="md-nav__link">
    Algorithms Implemented
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/jejjohnson/gp_model_zoo/edit/master/docs/software.md" title="Edit this page" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71,7.04C21.1,6.65 21.1,6 20.71,5.63L18.37,3.29C18,2.9 17.35,2.9 16.96,3.29L15.12,5.12L18.87,8.87M3,17.25V21H6.75L17.81,9.93L14.06,6.18L3,17.25Z" /></svg>
                  </a>
                
                
                  
                    


  


<a href="https://github.com/jejjohnson/gp_model_zoo/docs//software.md" title="software.md" class="md-content__button md-icon">
  Source
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
</a>
                  
                
                
                <h1 id="software">Software<a class="headerlink" href="#software" title="Permanent link">&para;</a></h1>
<p>Software for Gaussian processes (GPs) have really been improving for quite a while now. It is now a lot easier to not only to actually use the GP models, but also to modify them improve them.</p>
<h2 id="what-is-deep-learning">What is Deep Learning?<a class="headerlink" href="#what-is-deep-learning" title="Permanent link">&para;</a></h2>
<p>Before we get into the software, I just wanted to quickly define deep learning. A recent debate on <a href="https://twitter.com/yudapearl/status/1215174538087948288">twitter</a> got me thinking about an appropriate definition and it helped me think about how this definition relates to the software. It gave me perspective.</p>
<p><strong>Definition 1</strong> by Yann LeCun - <a href="https://twitter.com/ylecun/status/1215286749477384192">tweet</a> (paraphrased)</p>
<blockquote>
<p>Deep Learning is methodology: building a model by assembling parameterized modules into (possibly dynamic) graphs and optimizing it with gradient-based methods.</p>
</blockquote>
<p><strong>Definition II</strong> by Danilo Rezende - <a href="https://twitter.com/DeepSpiker/status/1209862283368816641">tweet</a> (paraphrased)</p>
<blockquote>
<p>Deep Learning is a collection of tools to build complex modular differentiable functions.</p>
</blockquote>
<p>These definitions are more or less the same: deep learning is a tool to facilitate gradient-based optimization scheme for models. The data we use, the exact way we construct it, and how we train it aren't really in the definition. Most people might think a DL tool is the ensemble of different neural networks like <a href="https://pbs.twimg.com/media/EOWJc2KWsAA8xDF?format=jpg&amp;name=4096x4096">these</a>. But from henceforth, I refer to DL in the terms of facilitating the development of those neural networks, not the network library itself.</p>
<p>So in terms of DL software, we need only a few components:</p>
<ul>
<li>Tensor structures</li>
<li>Automatic differentiation (AutoGrad)</li>
<li>Model Framework (Layers, etc)</li>
<li>Optimizers</li>
<li>Loss Functions</li>
</ul>
<p>Anything built on top of that can be special cases where we need special structures to create models for special cases. The simple example is a Multi-Layer Perceptron (MLP) model where we need some <code>weight</code> parameter, a <code>bias</code> parameter and an <code>activation</code> function. A library that allows you to train this model using an optimizer and a loss function, I would consider this autograd software (e.g. JAX). A library that has this functionality built-in (a.k.a. a <code>layer</code>), I would consider this deep learning software (e.g. TensorFlow, PyTorch). While the only difference is the level of encapsulation, the latter makes it much easier to build '<em>complex modular</em>' neural networks whereas the former, not so much. You could still do it with the autograd library but you would have to design your entire model structure from scratch as well. So, there are still a LOT of things we can do with parameters and autograd alone but I wouldn't classify it as DL software. This isn't super important in the grand scheme of things but I think it's important to think about when creating a programming language and/or package and thinking about the target user.</p>
<hr />
<h3 id="anatomy-of-good-dl-software">Anatomy of good DL software<a class="headerlink" href="#anatomy-of-good-dl-software" title="Permanent link">&para;</a></h3>
<p>Francios Chollet (the creator of <code>keras</code>) has been very vocal about the benefits of how TensorFlow caters to a broad audience ranging from applied users and algorithm developers. Both sides of the audience have different needs so building software for both audiences can very, very challenging. Below I have included a really interesting figure which highlights the axis of operations.</p>
<p align="center">

  <img src="https://keras-dev.s3.amazonaws.com/tutorials-img/spectrum-of-workflows.png" alt="drawing" width="800"/>
</p>

<p><strong>Photo Credit</strong>: Francois Chollet <a href="https://twitter.com/fchollet/status/1052228463300493312/photo/1">Tweet</a></p>
<p>As shown, there are two axis which define one way to split the DL software styles: the x-axis covers the <strong>model</strong> construction process and the y-axis covers the <strong>training</strong> process. I am sure that this is just one way to break apart DL software but I find it a good abstract way to look at it because I find that we can classify most use cases somewhere along this graph. I'll briefly outline a few below:</p>
<ul>
<li><strong>Case 1</strong>: All I care about is using a prebuilt model on some new data that my company has given me. I would probably fall somewhere on the upper right corner of the graph with the <code>Sequential</code> model and the built-in <code>training</code> scheme.</li>
<li><strong>Case II</strong>: I need a slightly more complex training scheme because I want to learn two models that share hidden nodes but they're not the same size. I also want to do some sort of cycle training, i.e. train one model first and then train the other. Then I would probably fall somewhere near the middle, and slightly to the right with the <code>Functional</code> model and a custom <code>training</code> scheme.</li>
<li><strong>Case III</strong>: I am a DL researcher and I need to control every single aspect of my model. I belong to the left and on the bottom with the full <code>subclass</code> model and completely custom <code>training</code> scheme.</li>
</ul>
<p>So there are many more special cases but by now you can imagine that most general cases can be found on the graph. I would like to stress that designing software to do all of these cases is not easy as these cases require careful design individually. It needs to be flexible.</p>
<p>Maybe I'm old school, but I like the modular way of design. So in essence, I think we should design libraries that focus on one aspect, one audience and do it well. I also like a standard practice and integration so that everything can fit together in the end and we can transfer information or products from one part to another. This is similar to how the Japanese revolutionized building cars by having one machine do one thing at a time and it all fit together via a standard assembly line. So in the end, I want people to be able to mix and match as they see fit. To try to please everyone with "<em>one DL library that rules them all</em>" seems a bit silly in my opinion because you're spreading out your resources. But then again, I've never built software from scratch and I'm not a mega coorperation like Google or Facebook, so what do I know? I'm just one user...in a sea of many.</p>
<blockquote>
<p>With great power, comes great responsibility - Uncle Ben</p>
</blockquote>
<p>On a side note, when you build popular libraries, you shape how a massive amount of people think about the problem. Just like expressiveness is only as good as your vocabulary and limited by your language, the software you create actively morphs how your users think about framing and solving their problems. Just something to think about.</p>
<hr />
<h3 id="convergence-of-the-libraries">Convergence of the Libraries<a class="headerlink" href="#convergence-of-the-libraries" title="Permanent link">&para;</a></h3>
<p>Originally, there was a lot of differences between the deep learning libraries, e.g. <code>static</code> v.s. <code>dynamic</code>, <code>Sequential</code> v.s. <code>Subclass</code>. But now they are all starting to converge or at least have similar ways of constructing models and training. Below is a quick example of 4 deep learning libraries. If you know your python DL libraries trivia, try and guess which library do you think it is. Click on the details below to find out the answer.</p>
<p align="center">
  <img src="https://pbs.twimg.com/media/DppB0xJUUAAjGi-?format=jpg&name=4096x4096" alt="drawing" width="800"/>
</p>

<p><strong>Photo Credit</strong>: Francois Chollet <a href="https://twitter.com/fchollet/status/1052228463300493312/photo/1">Tweet</a></p>
<details class="details"><summary><strong>Answer</strong></summary><p><center></p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Gluon</td>
<td>TensorFlow</td>
</tr>
<tr>
<td>PyTorch</td>
<td>Chainer</td>
</tr>
</tbody>
</table>
<p></center></p>
</details>
<p>It does begs the question: if all of the libraries are basically the same, why are their multiple libraries? That's a great question and I do not know the answer to that. I think options are good as competition generally stimulates innovation. But at some point, there should be a limit no? But then again, the companies backing each of these languages are quite huge (Google, Microsoft, Uber, Facebook, etc). So I'm sure they have more than enough employees to justify the existence of their own library. But then again, imagine if they all put their efforts into making one great library. It could be an epic success! Or an epic disaster. I guess we will never know.</p>
<p>So how to classify a library's worth is impossible because it's completely subjective. But I like this chart by Francois Chollet who put the different depths a package can go to in order to create a package that caters to different users. But libraries typically can be classified on this spectrum. The same breakdown of Deep Learning algorithms into Models and Training can be done for GPs as well. Since GPs aren't super mainstream yet, most modern large scale GP libraries will fall in the fully flexible category. But recently, with the edition of TensorFlow probability and Edward2, we have more modern GPs that will fall into the Easy to use category (but not necessarily easy to train...).</p>
<details class="danger"><summary>Rant</summary><p>One thing I don't like about the GP community is that it is quite split in terms of SOTA. This is reflected in the software. You'll have Andrew Gordon Wilson's spin-off that works a lot with Black-Box Matrix Multiplication (BBMMs) and then you'll have James Hensen's spin-off group that works a lot with methods of inducing points. The GPyTorch library scales amazingly but the GPFlow library has the best multi-output configuration I've ever seen. Either they don't know or they don't have time. But it would be nice if there was a one stop shop for all the algorithms so we can really get some cool benchmarks going when it comes to SOTA. Imagine something like <a href="https://github.com/OATML/bdl-benchmarks/tree/alpha/baselines/diabetic_retinopathy_diagnosis">this</a>, <a href="https://github.com/google/uncertainty-baselines">this</a> or <a href="https://github.com/dionhaefner/pyhpc-benchmarks">this</a> but with GPs from one library. I mean, I shouldn't complain, it's <strong>leagues</strong> better than it was. But we can do better...! :)</p>
</details>
<hr />
<h2 id="python-packages">Python Packages<a class="headerlink" href="#python-packages" title="Permanent link">&para;</a></h2>
<p>Below I list all of the GP packages available in Python. After this section, there will be more information on packages outside of the python ecosystem including some super intersting and well like <code>GaussianProcess.jl</code> for Julia and <code>Stan</code> as the universal programming language with many bindings. </p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>If you're new to python, then I highly recommend you check out my other resource gatherings. It can be found <a href="https://jejjohnson.github.io/research_journal/resources/"><strong>here</strong></a></p>
</div>
<h3 id="tldr-my-recommendations">TLDR - My Recommendations<a class="headerlink" href="#tldr-my-recommendations" title="Permanent link">&para;</a></h3>
<p><strong>Already Installed</strong> - <a href="https://scikit-learn.org/stable/modules/gaussian_process.html">scikit-learn</a></p>
<blockquote>
<p>If you're already installed python through anaconda of some sort then <code>scikit-learn</code> will be there close to being default. It should be in everyone's toolbox so it's really easy to whip out a GP method with this library. If you don't have a lot of data points (10-1_000) then just use this. It will do the job.</p>
</blockquote>
<p><strong>Python Standard</strong> - <a href="https://docs.pymc.io/">PyMC3</a></p>
<blockquote>
<p>This is the standard probabilistic programming language for doing Bayesian modeling in (more or less) standard Python. I personally think this library should also be in everyone's simple toolnox. The only thing that I don't like is that it uses <a href="https://docs.pymc.io/PyMC3_and_Theano.html">Theano</a>; it's not impossible but it's another API that you need to understand the moment you start trying to customize. However, the devs did a great job at making most of that API no necessary and it's very scalable on CPUs. So out of the box, you should be good! </p>
</blockquote>
<p><strong>From Scratch</strong> - <a href="https://github.com/google/jax">JAX</a></p>
<blockquote>
<p>If you like to do things from scratch in a very numpy-like way but also want all of the benefits of autograd on CPU/GPU/TPUs, then this is for you. If you want access to some distributions, you can always use <a href="https://pyro.ai/numpyro/">numpyro</a> or <a href="https://www.tensorflow.org/probability/examples/TensorFlow_Probability_on_JAX">tensorflow-probability</a> which both use JAX and have a JAX-backend respectively.</p>
</blockquote>
<p><strong>Standard / Researcher</strong> - <a href="https://www.tensorflow.org/">GPFlow</a></p>
<blockquote>
<p>I think the GPFlow library has the best balance of ease of use and customizability. It has a lot of nice little features that make it really nice to use out of the box while also allowing for customization. The only thing is that you're not going to get the most scalable nor does it inherit many SOTA methods in the GP community.</p>
</blockquote>
<p><strong>Researcher / Production</strong> - <a href="https://pytorch.org/">PyTorch</a></p>
<blockquote>
<p>If you're doing GP research and you really know how to program, then I suggest you use GPyTorch. It is currently the most popular library for doing GP research and it hosts an entire suite of SOTA ready to go. In addition, it is the most scalable library to date. While the developers made it super easy to play with on the surface, you need to dig deep and put on your coder hat in order to get to things under the hood. So maybe contributing stuff might have a barrier.</p>
</blockquote>
<div class="admonition warning">
<p class="admonition-title">Things Change</p>
<p>The machine learning community changes rapidly so any trends you observe are extremely volatile. Just like the machine learning literature, what's popular today can change within 6 months. So don't ever lock yourself in and stay flexible to cope with the changes. But also don't jump on bandwagons either as you'll be jumping every weekend. Keep a good balance and maintain your mental health.</p>
</div>
<hr />
<h3 id="scikit-learn"><a href="https://scikit-learn.org/stable/modules/gaussian_process.html">scikit-learn</a><a class="headerlink" href="#scikit-learn" title="Permanent link">&para;</a></h3>
<figure>
  <center>
  <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Scikit_learn_logo_small.svg/1200px-Scikit_learn_logo_small.svg.png" width="100" />
  <figcaption>Image caption</figcaption>
  </center>
</figure>

<p><a href="https://GitHub.com/scikit-learn/scikit-learn/stargazers/"><img alt="GitHub stars" src="https://img.shields.io/github/stars/scikit-learn/scikit-learn.svg?style=social&amp;label=Star&amp;maxAge=2592000" /></a> <a href="https://GitHub.com/scikit-learn/scikit-learn/issues/"><img alt="GitHub issues" src="https://img.shields.io/github/issues/scikit-learn/scikit-learn.svg" /></a> <a href="https://GitHub.com/scikit-learn/scikit-learn/issues?q=is%3Aissue+is%3Aclosed"><img alt="GitHub issues-closed" src="https://img.shields.io/github/issues-closed/scikit-learn/scikit-learn.svg" /></a> <a href="https://GitHub.com/scikit-learn/scikit-learn/pull/"><img alt="GitHub pull-requests" src="https://img.shields.io/github/issues-pr/scikit-learn/scikit-learn.svg" /></a> <a href="https://GitHub.com/scikit-learn/scikit-learn/pull/"><img alt="GitHub pull-requests closed" src="https://img.shields.io/github/issues-pr-closed/scikit-learn/scikit-learn.svg" /></a></p>
<p>So we can start with the one that everyone has installed on their machine. The GP implementation in the <a href="https://scikit-learn.org/stable/modules/gaussian_process.html">scikit-learn</a> library are already sufficient to get people started with GPs in scikit-learn. Often times when I'm data wrangling and I'm exploring possible algorithms, I'll already have the sklearn library installed in my conda environment so I typically start there myself especially for datasets with 100 points.</p>
<details class="details"><summary>Sample Code</summary><p>The sklearn implementation is as basic as it gets. If you are familiar with the scikit-learn API then you will have no problems using the GPR module. It's a three step process with very little things to change.</p>
<div class="tabbed-set" data-tabs="1:3"><input checked="checked" id="__tabbed_1_1" name="__tabbed_1" type="radio" /><label for="__tabbed_1_1">Model</label><div class="tabbed-content">
<div class="highlight"><pre><span></span><code><span class="c1"># initialize kernel function</span>
<span class="n">kernel1</span> <span class="o">=</span> <span class="n">RBF</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span> \
<span class="n">kernel2</span> <span class="o">=</span> <span class="n">WhiteKernel</span><span class="p">(</span><span class="n">noise_level</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">kernel1</span> <span class="o">+</span> <span class="n">kernel2</span>

<span class="c1"># initialize noise parameter</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">1e-5</span>

<span class="c1"># initialize optimizer</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="s2">&quot;fmin_l_bfgs_b&quot;</span>

<span class="c1"># initialize GP model</span>
<span class="n">gpr_model</span> <span class="o">=</span> <span class="n">GaussianProcessRegressor</span><span class="p">(</span>
  <span class="n">kernel</span><span class="o">=</span><span class="n">kernel_gpml</span><span class="p">,</span>
  <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span>
  <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> 
<span class="p">)</span>
</code></pre></div>

</div>
<input id="__tabbed_1_2" name="__tabbed_1" type="radio" /><label for="__tabbed_1_2">Training</label><div class="tabbed-content">
<div class="highlight"><pre><span></span><code><span class="c1"># train GP model</span>
<span class="n">gpr_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">)</span>
</code></pre></div>

</div>
<input id="__tabbed_1_3" name="__tabbed_1" type="radio" /><label for="__tabbed_1_3">Predictions</label><div class="tabbed-content">
<div class="highlight"><pre><span></span><code><span class="c1"># get predictions</span>
<span class="n">y_pred</span><span class="p">,</span> <span class="n">y_std</span> <span class="o">=</span> <span class="n">gpr_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xtest</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>

</div>
</div>
<!-- tabs:end -->

</details>
<p>Again, this is the simplest API you will find and for small data problems, you'll find that this works fine out-of-the-box. I highly recommend this when starting especially if you're not a GP connoisseur. What I showed above is as complicated as it gets. Any more customization outside of this is a bit difficult as the scikit-learn API for GPs isn't very modular and wasn't designed as such. But as a first pass, it's good enough.</p>
<div class="admonition tip">
<p class="admonition-title">Best Resource</p>
<ul>
<li>By far the best you'll see is the <a href="https://scikit-learn.org/stable/modules/gaussian_process.html#gaussian-process">scikit-learn</a> documentation.</li>
<li>If you're feeling adventurous, you can check out how some people have extended this with <a href="https://github.com/jmetzen/gp_extras">additional kernels</a>.</li>
</ul>
</div>
<div class="admonition info">
<p class="admonition-title">Verdict</p>
<p>✔️ Simple</p>
<p>✔️ Standard</p>
<p>❌ Simple. No SOTA. No Sparse models. No tricks.</p>
<p>❌ Hard to modify individual parts.</p>
<p>❌ No Autograd</p>
</div>
<hr />
<h3 id="gpy"><a href="https://sheffieldml.github.io/GPy/">GPy</a><a class="headerlink" href="#gpy" title="Permanent link">&para;</a></h3>
<p><a href="https://GitHub.com/SheffieldML/GPy/stargazers/"><img alt="GitHub stars" src="https://img.shields.io/github/stars/SheffieldML/GPy.svg?style=social&amp;label=Star&amp;maxAge=2592000" /></a> <a href="https://GitHub.com/SheffieldML/GPy/issues/"><img alt="GitHub issues" src="https://img.shields.io/github/issues/SheffieldML/GPy.svg" /></a> <a href="https://GitHub.com/SheffieldML/GPy/issues?q=is%3Aissue+is%3Aclosed"><img alt="GitHub issues-closed" src="https://img.shields.io/github/issues-closed/SheffieldML/GPy.svg" /></a> <a href="https://GitHub.com/SheffieldML/GPy/pull/"><img alt="GitHub pull-requests" src="https://img.shields.io/github/issues-pr/SheffieldML/GPy.svg" /></a> <a href="https://GitHub.com/SheffieldML/GPy/pull/"><img alt="GitHub pull-requests closed" src="https://img.shields.io/github/issues-pr-closed/SheffieldML/GPy.svg" /></a></p>
<p>GPy is the most <strong>comprehensive research library</strong> I have found to date. It has the most number of different special GP "corner case" algorithms of any package available. The GPy <a href="https://gpy.readthedocs.io/en/deploy/_modules/GPy/examples/regression.html">examples</a> and <a href="https://nbviewer.jupyter.org/github/SheffieldML/notebook/blob/master/GPy/index.ipynb">tutorials</a> are very comprehensive. The major caveat is that the <a href="https://gpy.readthedocs.io/en/deploy/">documentation</a> is very difficult to navigate. I also found the code base to be a bit difficult to really understand what's going on because there is no automatic differentiation to reduce the computations so there can be a bit of redundancy. I typically wrap some typical GP algorithms with some common parameters that I use within the sklearn <code>.fit()</code>, <code>.predict()</code>, <code>.score()</code> framework and call it a day. The standard algorithms will include the Exact GP, the Sparse GP, and Bayesian GPLVM.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This library does not get updated very often so you will likely run into very silly bugs if you don't use strict package versions that are recommended. There are rumors of a GPy2 library that's based on <a href="https://github.com/amzn/MXFusion">MXFusion</a> but I have failed to see anything concrete yet.</p>
</div>
<p>??? note "Idea:
    <strong>Idea</strong>: Some of the main algorithms such as the sparse GP implementations are mature enough to be dumped into the sklearn library. For small-medium data problems, I think this would be extremely beneficial to the community. Some of the key papers like the (e.g. the <a href="https://papers.nips.cc/paper/2857-sparse-gaussian-processes-using-pseudo-inputs">FITC-SGP</a>, <a href="http://proceedings.mlr.press/v5/titsias09a.html">VFE-SGP</a>, <a href="https://dl.acm.org/doi/10.1145/1273496.1273546">Heteroscedastic GP</a>, <a href="https://dl.acm.org/doi/10.5555/2981345.2981387">GP-LVM</a>) certainly pass some of the <a href="https://scikit-learn.org/stable/faq.html#what-are-the-inclusion-criteria-for-new-algorithms">strict sklearn criteria</a>. But I suspect that it wouldn't be a joy to code because you would need to do some of the gradients from scratch. I do feel like it might make GPs a bit more popular if some of the mainstream methods were included in the scikit-learn library.</p>
<details class="details"><summary>Sample Code</summary><p>The GPy implementation is also very basic. If you are familiar with the scikit-learn API then you will have no problems using the GPR module. It's a three step process with very little things to change.</p>
<div class="tabbed-set" data-tabs="2:3"><input checked="checked" id="__tabbed_2_1" name="__tabbed_2" type="radio" /><label for="__tabbed_2_1">Model</label><div class="tabbed-content">
<div class="highlight"><pre><span></span><code><span class="c1"># define kernel function</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">GPy</span><span class="o">.</span><span class="n">kern</span><span class="o">.</span><span class="n">RBF</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">variance</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">lengthscale</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>

<span class="c1"># initialize GP model</span>
<span class="n">gpr_model</span> <span class="o">=</span> <span class="n">GPy</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">GPRegression</span><span class="p">(</span>
  <span class="n">Xtrain</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span>
  <span class="n">kern</span><span class="o">=</span><span class="n">kernel</span>
<span class="p">)</span>
</code></pre></div>

</div>
<input id="__tabbed_2_2" name="__tabbed_2" type="radio" /><label for="__tabbed_2_2">Training</label><div class="tabbed-content">
<div class="highlight"><pre><span></span><code><span class="c1"># train GP model</span>
<span class="n">gpr_model</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">messages</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>

</div>
<input id="__tabbed_2_3" name="__tabbed_2" type="radio" /><label for="__tabbed_2_3">Predictions</label><div class="tabbed-content">
<div class="highlight"><pre><span></span><code><span class="c1"># get predictions</span>
<span class="n">y_pred</span><span class="p">,</span> <span class="n">y_std</span> <span class="o">=</span> <span class="n">gpr_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xtest</span><span class="p">)</span>
</code></pre></div>

</div>
</div>
</details>
<p>So as you can see, the API is very similar to the scikit-learn API with some small differences; the main one being that you have to initiate the GP model with the data. The rest is fairly similar. You should definitely take a look at the GPy docs if you are interested in some more advanced examples.</p>
<div class="admonition tip">
<p class="admonition-title">Best Resource</p>
<ul>
<li>By far the best you'll find are the GP Summer school <a href="http://gpss.cc/gpss20/labs">labs</a> that happen <a href="http://gpss.cc/">every year</a>. (<a href="http://gpss.cc/gpss20/"><strong>This year is virtual!</strong></a>)</li>
<li>They have a lot of <a href="https://gpy.readthedocs.io/en/devel/GPy.examples.html">good examples</a> on the website.</li>
<li>The documentation is <a href="https://gpy.readthedocs.io/en/devel/index.html">very extensive</a> but very difficult to get to the nitty gritty details.</li>
</ul>
</div>
<div class="admonition info">
<p class="admonition-title">Verdict</p>
<p>✔️ Simple</p>
<p>✔️ Legacy</p>
<p>❌ Not industry battle-tested.</p>
<p>❌ No Autograd</p>
</div>
<hr />
<h3 id="gpytorch"><a href="https://gpytorch.ai/">GPyTorch</a><a class="headerlink" href="#gpytorch" title="Permanent link">&para;</a></h3>
<p><a href="https://GitHub.com/cornellius-gp/gpytorch/stargazers/"><img alt="GitHub stars" src="https://img.shields.io/github/stars/cornellius-gp/gpytorch.svg?style=social&amp;label=Star&amp;maxAge=2592000" /></a> <a href="https://GitHub.com/cornellius-gp/gpytorch/issues/"><img alt="GitHub issues" src="https://img.shields.io/github/issues/cornellius-gp/gpytorch.svg" /></a> <a href="https://GitHub.com/cornellius-gp/gpytorch/issues?q=is%3Aissue+is%3Aclosed"><img alt="GitHub issues-closed" src="https://img.shields.io/github/issues-closed/cornellius-gp/gpytorch.svg" /></a> <a href="https://GitHub.com/cornellius-gp/gpytorch/pull/"><img alt="GitHub pull-requests" src="https://img.shields.io/github/issues-pr/cornellius-gp/gpytorch.svg" /></a> <a href="https://GitHub.com/cornellius-gp/gpytorch/pull/"><img alt="GitHub pull-requests closed" src="https://img.shields.io/github/issues-pr-closed/cornellius-gp/gpytorch.svg" /></a></p>
<p>This is my defacto library for <strong>applying GPs</strong> to large scale data. Anything above 10,000 points, and I will resort to this library. It has GPU acceleration and a large suite of different GP algorithms depending upon your problem. I think this is currently the dominant GP library for actually using GPs and I highly recommend it for utility. They have many options available ranging from latent variables to multi-outputs. Recently they've just revamped their entire library and documentation with some I still find it a bit difficult to really customize anything under the hood. But if you can figure out how to mix and match each of the modular parts, then it should work for you.</p>
<details class="details"><summary>Sample Code</summary><p>In GPyTorch, the library follows the pythonic way of coding that became super popular from deep learning frameworks such as Chainer and subsequently PyTorch. It consists of a 4 step process which is seen in the snippet below.</p>
<p><strong><a href="https://docs.gpytorch.ai/en/v1.2.0/examples/01_Exact_GPs/Simple_GP_Regression.html">Source</a></strong> - GPyTorch Docs</p>
<div class="tabbed-set" data-tabs="3:3"><input checked="checked" id="__tabbed_3_1" name="__tabbed_3" type="radio" /><label for="__tabbed_3_1">Model</label><div class="tabbed-content">
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">MyGP</span><span class="p">(</span><span class="n">gpytorch</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">ExactGP</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">)</span>

        <span class="c1"># Mean Function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean_module</span> <span class="o">=</span> <span class="n">gpytorch</span><span class="o">.</span><span class="n">means</span><span class="o">.</span><span class="n">ZeroMean</span><span class="p">()</span>

        <span class="c1"># Kernel Function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">covar_module</span> <span class="o">=</span> <span class="n">gpytorch</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">ScaleKernel</span><span class="p">(</span><span class="n">gpytorch</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">RBFKernel</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_module</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">covar</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">covar_module</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">gpytorch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">MultivariateNormal</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">covar</span><span class="p">)</span>

<span class="c1"># train_x = ...; train_y = ...</span>
<span class="n">likelihood</span> <span class="o">=</span> <span class="n">gpytorch</span><span class="o">.</span><span class="n">likelihoods</span><span class="o">.</span><span class="n">GaussianLikelihood</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyGP</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">)</span>
</code></pre></div>

</div>
<input id="__tabbed_3_2" name="__tabbed_3" type="radio" /><label for="__tabbed_3_2">Training</label><div class="tabbed-content">
<div class="highlight"><pre><span></span><code><span class="c1"># Put model in train mode</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="n">likelihood</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

<span class="c1"># Define optimizer</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="c1"># Define loss function the marginal log likelihood</span>
<span class="n">mll</span> <span class="o">=</span> <span class="n">gpytorch</span><span class="o">.</span><span class="n">mlls</span><span class="o">.</span><span class="n">ExactMarginalLogLikelihood</span><span class="p">(</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>

<span class="c1"># training step</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">training_iter</span><span class="p">):</span>
    <span class="c1"># Zero gradients from previous iteration</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="c1"># Output from model</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">train_x</span><span class="p">)</span>
    <span class="c1"># Calc loss</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">mll</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>
    <span class="c1">#  backprop gradients</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Iter </span><span class="si">%d</span><span class="s1">/</span><span class="si">%d</span><span class="s1"> - Loss: </span><span class="si">%.3f</span><span class="s1">   lengthscale: </span><span class="si">%.3f</span><span class="s1">   noise: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span>
        <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">training_iter</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
        <span class="n">model</span><span class="o">.</span><span class="n">covar_module</span><span class="o">.</span><span class="n">base_kernel</span><span class="o">.</span><span class="n">lengthscale</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
        <span class="n">model</span><span class="o">.</span><span class="n">likelihood</span><span class="o">.</span><span class="n">noise</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="p">))</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</code></pre></div>

</div>
<input id="__tabbed_3_3" name="__tabbed_3" type="radio" /><label for="__tabbed_3_3">Predictions</label><div class="tabbed-content">
<div class="highlight"><pre><span></span><code><span class="c1"># get the predictive mean class</span>
<span class="n">f_preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">test_x</span><span class="p">)</span>

<span class="c1"># can do the same with we want the noise model</span>
<span class="n">y_preds</span> <span class="o">=</span> <span class="n">likelihood</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">test_x</span><span class="p">))</span>

<span class="c1"># predictive mean</span>
<span class="n">f_mean</span> <span class="o">=</span> <span class="n">f_preds</span><span class="o">.</span><span class="n">mean</span>

<span class="c1"># predictive variance</span>
<span class="n">f_var</span> <span class="o">=</span> <span class="n">f_preds</span><span class="o">.</span><span class="n">variance</span>

<span class="c1"># predictive covariance</span>
<span class="n">f_covar</span> <span class="o">=</span> <span class="n">f_preds</span><span class="o">.</span><span class="n">covariance_matrix</span>

<span class="c1"># sample from posterior distribution</span>
<span class="n">f_samples</span> <span class="o">=</span> <span class="n">f_preds</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">sample_shape</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span><span class="mi">1000</span><span class="p">,))</span>
</code></pre></div>

</div>
</div>
</details>
<p>I am only scratching the surface with this quick snippet. But I wanted to highlight how this fits into</p>
<div class="admonition tip">
<p class="admonition-title">Best Resource</p>
<ul>
<li>By far the best you'll see are form the <a href="https://gpytorch.ai/"><strong>GPyTorch documentation</strong></a>:<ul>
<li><a href="https://docs.gpytorch.ai/en/v1.2.0/examples/01_Exact_GPs/Simple_GP_Regression.html">The Tutorial</a></li>
<li><a href="https://docs.gpytorch.ai/en/v1.2.0/examples/00_Basic_Usage/index.html">The Examples</a>. There are a lot.</li>
</ul>
</li>
<li>
<p><a href="https://github.com/bayesgroup/deepbayes-2019/blob/master/seminars/day4/gp/GP/gp_solution.ipynb">Gaussian Processes (GP) with GPyTorch</a> by <a href="https://bayesgroup.ru/">DeepBayes.ru</a></p>
<blockquote>
<p>A good tutorial from an outside perspective. Similar to the GPy tutorial.</p>
</blockquote>
</li>
</ul>
</div>
<div class="admonition info">
<p class="admonition-title">Verdict</p>
<p>✔️ All working pieces to GP Model customizable</p>
<p>✔️ Lots of SOTA models</p>
<p>✔️ Super responsive devs</p>
<p>✔️ Integration with PyTorch and Pyro</p>
<p>❌ Difficult for absolute beginners</p>
<p>❌ Very difficult to contribute actual code</p>
<p>❌ Boilerplate Code</p>
</div>
<hr />
<h3 id="gpflow"><a href="https://github.com/GPflow/GPflow">GPFlow</a><a class="headerlink" href="#gpflow" title="Permanent link">&para;</a></h3>
<figure>
  <center>
  <img src="https://github.com/GPflow/GPflow/raw/develop/doc/source/_static/gpflow_logo.svg" width="100" />
  <figcaption>GPFlow Logo</figcaption>
  </center>
</figure>

<p><a href="https://GitHub.com/GPflow/GPflow/stargazers/"><img alt="GitHub stars" src="https://img.shields.io/github/stars/GPflow/GPflow.svg?style=social&amp;label=Star&amp;maxAge=2592000" /></a> <a href="https://GitHub.com/GPflow/GPflow/issues/"><img alt="GitHub issues" src="https://img.shields.io/github/issues/GPflow/GPflow.svg" /></a> <a href="https://GitHub.com/GPflow/GPflow/issues?q=is%3Aissue+is%3Aclosed"><img alt="GitHub issues-closed" src="https://img.shields.io/github/issues-closed/GPflow/GPflow.svg" /></a> <a href="https://GitHub.com/GPflow/GPflow/pull/"><img alt="GitHub pull-requests" src="https://img.shields.io/github/issues-pr/GPflow/GPflow.svg" /></a> <a href="https://GitHub.com/GPflow/GPflow/pull/"><img alt="GitHub pull-requests closed" src="https://img.shields.io/github/issues-pr-closed/GPflow/GPflow.svg" /></a></p>
<p>What Pyro is to PyTorch, GPFlow is to TensorFlow. This library is the successor to the GPy library. It is very comprehensive with a lot of SOTA algorithms. I definitely think ifA few of the devs from GPy went to GPFlow so it has a very similar style as GPy. But it is a lot cleaner due to the use of autograd which eliminates all of the code used to track the gradients. Many researchers use this library as a backend for their own research code so I would say it is the second most used library in the research domain. I didn't find it particularly easy to customize in tensorflow =&lt;1.1 because of the session tracking which wasn't clear to me from the beginning. But now with the addition of tensorflow 2.0 and GPFlow adopting that new framework, I am eager to try it out again. They have a new <a href="https://github.com/GPflow/GPflow#the-gpflow-community">public slack group</a> so their network is going to grow hopefully.</p>
<!-- tabs:start -->

<details class="details"><summary>Sample Code</summary><div class="tabbed-set" data-tabs="4:2"><input checked="checked" id="__tabbed_4_1" name="__tabbed_4" type="radio" /><label for="__tabbed_4_1">Model</label><div class="tabbed-content">
<p><strong>Source</strong>: <a href="https://gpflow.readthedocs.io/en/develop/notebooks/basics/regression.html">GPFlow Docs</a></p>
<div class="highlight"><pre><span></span><code><span class="c1"># kernel function</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">Matern52</span><span class="p">()</span>

<span class="c1"># mean function</span>
<span class="n">meanf</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">mean_functions</span><span class="o">.</span><span class="n">Linear</span><span class="p">()</span>

<span class="c1"># define GP model</span>
<span class="n">gpr_model</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">GPR</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">),</span> <span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span> <span class="n">mean_function</span><span class="o">=</span><span class="n">meanf</span>
<span class="p">)</span>
</code></pre></div>

</div>
<input id="__tabbed_4_2" name="__tabbed_4" type="radio" /><label for="__tabbed_4_2">Training</label><div class="tabbed-content">
<div class="highlight"><pre><span></span><code><span class="c1"># define optimizer</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Scipy</span><span class="p">()</span>

<span class="c1"># optimize function</span>
<span class="n">num_steps</span> <span class="o">=</span> <span class="mi">1_000</span>

<span class="n">opt_logs</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span>
    <span class="n">m</span><span class="o">.</span><span class="n">training_loss</span><span class="p">,</span>
    <span class="n">m</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">,</span>
    <span class="n">options</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">maxiter</span><span class="o">=</span><span class="n">num_steps</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div>

</div>
</div>
</details>
<div class="admonition tip">
<p class="admonition-title">Best Resource</p>
<ul>
<li>By far the best you'll see are form the <a href="https://gpflow.readthedocs.io/en/develop/index.html"><strong>GPFlow documentation</strong></a>:<ul>
<li><a href="https://gpflow.readthedocs.io/en/develop/notebooks/intro.html">Tutorials</a></li>
<li><a href="https://gpflow.readthedocs.io/en/develop/notebooks/intro_to_gpflow2.html">Integration with TensorFlow</a>. There are a lot.</li>
</ul>
</li>
<li><a href="https://github.com/GPflow/GPflow#slack-workspace">Slack Channel</a></li>
<li><a href="https://stackoverflow.com/questions/tagged/gpflow">StackOverFlow</a></li>
</ul>
</div>
<div class="admonition info">
<p class="admonition-title">Verdict</p>
<p>✔️ Customizable <strong>BUT</strong> GPy Familiar</p>
<p>✔️ Lots of SOTA models</p>
<p>✔️ Super responsive devs</p>
<p>✔️ Integration with TensorFlow and TensorFlow-probability</p>
<p>❌ Difficult for absolute beginners</p>
<p>❌ Very difficult to contribute actual code</p>
<p>❌ Missing some SOTA</p>
</div>
<hr />
<h2 id="other-libraries">Other Libraries<a class="headerlink" href="#other-libraries" title="Permanent link">&para;</a></h2>
<p><center></p>
<table>
<thead>
<tr>
<th align="center">Name</th>
<th align="center">Language</th>
<th align="center">Comments</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="https://docs.pymc.io/nb_examples/index.html">PyMC3</a></td>
<td align="center">Python (Theano)</td>
<td align="center">Probabilistic programming with exact and sparse implementations and HMC/NUTS inference.</td>
</tr>
<tr>
<td align="center"><a href="https://github.com/google/edward2/tree/master/edward2/tensorflow/layers">Edward2</a></td>
<td align="center">Python (TensorFlow)</td>
<td align="center">Implements drop-in GPs and Sparse GPs as keras layers.</td>
</tr>
<tr>
<td align="center"><a href="https://www.mathworks.com/help/stats/gaussian-process-regression-models.html">MATLAB</a></td>
<td align="center">MATLAB</td>
<td align="center">They have their own native implementations (straight from Rasmussen)</td>
</tr>
<tr>
<td align="center"><a href="https://github.com/alshedivat/gpml">gpml</a></td>
<td align="center">MATLAB</td>
<td align="center">Examples and code used in Rasmussen &amp; Williams</td>
</tr>
<tr>
<td align="center"><a href="https://github.com/gpstuff-dev/gpstuff">GPstuff</a></td>
<td align="center">MATLAB</td>
<td align="center">A library with a wide range of inference methods. Including HMC.</td>
</tr>
<tr>
<td align="center"><a href="https://github.com/STOR-i/GaussianProcesses.jl">GaussianProcess.jl</a></td>
<td align="center">Julia</td>
<td align="center">GP library utilising Julia's fast JIT compilation</td>
</tr>
<tr>
<td align="center"><a href="https://mc-stan.org/">Stan</a></td>
<td align="center">R, Python, shell, MATLAB, Julia, Stata</td>
<td align="center">Probabilistic programming using MCMC that can be easily be used to model GPs</td>
</tr>
</tbody>
</table>
<!-- tabs:end -->

<!--
**Source**: [Edward2 Github](https://github.com/google/edward2/tree/master/edward2/tensorflow/layers)

---
## Library Classification

Below you have a few plots which show the complexity vs flexible scale of different architectures for software. The goal of keras and tensorflow is to accommodate ends of that scale. 


<p align="center">
  <img src="https://keras-dev.s3.amazonaws.com/tutorials-img/model-building-spectrum.png" alt="drawing" width="800"/>
</p>

**Figure**: Photo Credit - Francois Chollet

<p align="center">
  <img src="https://keras-dev.s3.amazonaws.com/tutorials-img/model-training-spectrum.png" alt="drawing" width="800"/>
</p>

**Figure**: Photo Credit - Francois Chollet

 -->

<hr />
<h2 id="gpu-support">GPU Support<a class="headerlink" href="#gpu-support" title="Permanent link">&para;</a></h2>
<p><center></p>
<table>
<thead>
<tr>
<th><strong>Package</strong></th>
<th><strong>Backend</strong></th>
<th><strong>GPU Support</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>GPy</td>
<td>Numpy</td>
<td>✓</td>
</tr>
<tr>
<td>Scikit-Learn</td>
<td>Numpy</td>
<td>✗</td>
</tr>
<tr>
<td>PyMC3</td>
<td>Theano</td>
<td>✓</td>
</tr>
<tr>
<td>TensorFlow (Probability)</td>
<td>TensorFlow</td>
<td>✓</td>
</tr>
<tr>
<td>Edward</td>
<td>TensorFlow</td>
<td>✓</td>
</tr>
<tr>
<td>GPFlow</td>
<td>TensorFlow</td>
<td>✓</td>
</tr>
<tr>
<td>Pyro.contrib</td>
<td>PyTorch</td>
<td>✓</td>
</tr>
<tr>
<td>GPyTorch</td>
<td>PyTorch</td>
<td>✓</td>
</tr>
<tr>
<td>PyMC4</td>
<td>TensorFlow</td>
<td>✓</td>
</tr>
</tbody>
</table>
<p></center></p>
<hr />
<h2 id="algorithms-implemented">Algorithms Implemented<a class="headerlink" href="#algorithms-implemented" title="Permanent link">&para;</a></h2>
<p><center></p>
<table>
<thead>
<tr>
<th><strong>Package</strong></th>
<th><strong>GPy</strong></th>
<th><strong>Scikit-Learn</strong></th>
<th><strong>PyMC3</strong></th>
<th><strong>TensorFlow (Probability)</strong></th>
<th><strong>GPFlow</strong></th>
<th><strong>Pyro</strong></th>
<th><strong>GPyTorch</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>Exact</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td>Moment Matching GP</td>
<td>✓</td>
<td>✗</td>
<td>✓</td>
<td>✗</td>
<td>S</td>
<td>S</td>
<td>✓</td>
</tr>
<tr>
<td>SparseGP - FITC</td>
<td>✓</td>
<td>✗</td>
<td>✓</td>
<td>✗</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td>SparseGP - PEP</td>
<td>✓</td>
<td>✗</td>
<td>✗</td>
<td>✗</td>
<td>✗</td>
<td>✗</td>
<td>✗</td>
</tr>
<tr>
<td>SparseSP - VFE</td>
<td>✓</td>
<td>✗</td>
<td>✗</td>
<td>✗</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td>Variational GP</td>
<td>✓</td>
<td>✗</td>
<td>✗</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✗</td>
</tr>
<tr>
<td>Stochastic Variational GP</td>
<td>✓</td>
<td>✗</td>
<td>✗</td>
<td>S</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td>Deep GP</td>
<td>✗</td>
<td>✗</td>
<td>✗</td>
<td>S</td>
<td>S</td>
<td>✓</td>
<td>D</td>
</tr>
<tr>
<td>Deep Kernel Learning</td>
<td>✗</td>
<td>✗</td>
<td>✗</td>
<td>S</td>
<td>S</td>
<td>S</td>
<td>✓</td>
</tr>
<tr>
<td>GPLVM</td>
<td>✓</td>
<td>✗</td>
<td>✗</td>
<td>✗</td>
<td>✗</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td>Bayesian GPLVM</td>
<td>✓</td>
<td>✗</td>
<td>✗</td>
<td>✗</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td>SKI/KISS</td>
<td></td>
<td>✗</td>
<td>✗</td>
<td>✗</td>
<td>✗</td>
<td>✗</td>
<td>✓</td>
</tr>
<tr>
<td>LOVE</td>
<td>✗</td>
<td>✗</td>
<td>✗</td>
<td>✗</td>
<td>✗</td>
<td>✗</td>
<td>✓</td>
</tr>
</tbody>
</table>
<p></center></p>
<p><strong>Key</strong></p>
<table>
<thead>
<tr>
<th>Symbol</th>
<th>Status</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>✓</strong></td>
<td><strong>Implemented</strong></td>
</tr>
<tr>
<td>✗</td>
<td>Not Implemented</td>
</tr>
<tr>
<td>D</td>
<td>Development</td>
</tr>
<tr>
<td>S</td>
<td>Supported</td>
</tr>
<tr>
<td>S(?)</td>
<td>Maybe Supported</td>
</tr>
</tbody>
</table>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid" aria-label="Footer">
        
          <a href=".." title="Home" class="md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20,11V13H8L13.5,18.5L12.08,19.92L4.16,12L12.08,4.08L13.5,5.5L8,11H20Z" /></svg>
            </div>
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Home
              </div>
            </div>
          </a>
        
        
          <a href="../intro/" title="Intro to GPs" class="md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Intro to GPs
              </div>
            </div>
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4,11V13H16L10.5,18.5L11.92,19.92L19.84,12L11.92,4.08L10.5,5.5L16,11H4Z" /></svg>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2020 J. Emmanuel Johnson
          </div>
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
  <div class="md-footer-social">
    
      
      
      <a href="https://github.com/jejjohnson" target="_blank" rel="noopener" title="github.com" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
      </a>
    
      
      
      <a href="https://twitter.com/jejjohnson" target="_blank" rel="noopener" title="twitter.com" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
      </a>
    
      
      
      <a href="https://linkedin.com/in/jejjohnson" target="_blank" rel="noopener" title="linkedin.com" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
      </a>
    
      
      
      <a href="https://jejjohnson.netlify.app" target="_blank" rel="noopener" title="jejjohnson.netlify.app" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path d="M336.5 160C322 70.7 287.8 8 248 8s-74 62.7-88.5 152h177zM152 256c0 22.2 1.2 43.5 3.3 64h185.3c2.1-20.5 3.3-41.8 3.3-64s-1.2-43.5-3.3-64H155.3c-2.1 20.5-3.3 41.8-3.3 64zm324.7-96c-28.6-67.9-86.5-120.4-158-141.6 24.4 33.8 41.2 84.7 50 141.6h108zM177.2 18.4C105.8 39.6 47.8 92.1 19.3 160h108c8.7-56.9 25.5-107.8 49.9-141.6zM487.4 192H372.7c2.1 21 3.3 42.5 3.3 64s-1.2 43-3.3 64h114.6c5.5-20.5 8.6-41.8 8.6-64s-3.1-43.5-8.5-64zM120 256c0-21.5 1.2-43 3.3-64H8.6C3.2 212.5 0 233.8 0 256s3.2 43.5 8.6 64h114.6c-2-21-3.2-42.5-3.2-64zm39.5 96c14.5 89.3 48.7 152 88.5 152s74-62.7 88.5-152h-177zm159.3 141.6c71.4-21.2 129.4-73.7 158-141.6h-108c-8.8 56.9-25.6 107.8-50 141.6zM19.3 352c28.6 67.9 86.5 120.4 158 141.6-24.4-33.8-41.2-84.7-50-141.6h-108z"/></svg>
      </a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/vendor.f81b9e8b.min.js"></script>
      <script src="../assets/javascripts/bundle.23546af0.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents"}</script>
      
      <script>
        app = initialize({
          base: "..",
          features: [],
          search: Object.assign({
            worker: "../assets/javascripts/worker/search.58d22e8e.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
        <script src="../javascripts/extra.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
      
    
  </body>
</html>