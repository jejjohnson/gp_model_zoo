


<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Large Scale 1D Example using Different GP Libraries">
      
      
        <link rel="canonical" href="https://jejjohnson.github.io/gp_model_zoo/demos/1d_example_ls/">
      
      
        <meta name="author" content="J. Emmanuel Johnson">
      
      <link rel="shortcut icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-5.1.3">
    
    
      
        <title>1D Example (Large Scale)</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.62d34fff.min.css">
      
        <link rel="stylesheet" href="../../assets/stylesheets/palette.c8acc6db.min.css">
      
      
        
        
        <meta name="theme-color" content="#ef5350">
      
    
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=source+code+pro:300,400,400i,700%7Csource+code+pro&display=fallback">
        <style>body,input{font-family:"source code pro",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"source code pro",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
      <link rel="stylesheet" href="../../css/ansi-colours.css">
    
      <link rel="stylesheet" href="../../css/jupyter-cells.css">
    
      <link rel="stylesheet" href="../../css/pandas-dataframe.css">
    
    
      
    
    
  </head>
  
  
    
    
    <body dir="ltr" data-md-color-primary="red" data-md-color-accent="black">
  
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#large-scale-1d-example-walk-through" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href="https://jejjohnson.github.io/gp_model_zoo" title="GP Model Zoo" class="md-header-nav__button md-logo" aria-label="GP Model Zoo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12,8A3,3 0 0,0 15,5A3,3 0 0,0 12,2A3,3 0 0,0 9,5A3,3 0 0,0 12,8M12,11.54C9.64,9.35 6.5,8 3,8V19C6.5,19 9.64,20.35 12,22.54C14.36,20.35 17.5,19 21,19V8C17.5,8 14.36,9.35 12,11.54Z" /></svg>

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3,6H21V8H3V6M3,11H21V13H3V11M3,16H21V18H3V16Z" /></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      
        <div class="md-header-nav__ellipsis">
          <span class="md-header-nav__topic md-ellipsis">
            GP Model Zoo
          </span>
          <span class="md-header-nav__topic md-ellipsis">
            
              1D Example (Large Scale)
            
          </span>
        </div>
      
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5,3A6.5,6.5 0 0,1 16,9.5C16,11.11 15.41,12.59 14.44,13.73L14.71,14H15.5L20.5,19L19,20.5L14,15.5V14.71L13.73,14.44C12.59,15.41 11.11,16 9.5,16A6.5,6.5 0 0,1 3,9.5A6.5,6.5 0 0,1 9.5,3M9.5,5C7,5 5,7 5,9.5C5,12 7,14 9.5,14C12,14 14,12 14,9.5C14,7 12,5 9.5,5Z" /></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active">
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5,3A6.5,6.5 0 0,1 16,9.5C16,11.11 15.41,12.59 14.44,13.73L14.71,14H15.5L20.5,19L19,20.5L14,15.5V14.71L13.73,14.44C12.59,15.41 11.11,16 9.5,16A6.5,6.5 0 0,1 3,9.5A6.5,6.5 0 0,1 9.5,3M9.5,5C7,5 5,7 5,9.5C5,12 7,14 9.5,14C12,14 14,12 14,9.5C14,7 12,5 9.5,5Z" /></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20,11V13H8L13.5,18.5L12.08,19.92L4.16,12L12.08,4.08L13.5,5.5L8,11H20Z" /></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19,6.41L17.59,5L12,10.59L6.41,5L5,6.41L10.59,12L5,17.59L6.41,19L12,13.41L17.59,19L19,17.59L13.41,12L19,6.41Z" /></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header-nav__source">
        
<a href="https://github.com/jejjohnson/gp_model_zoo/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    jejjohnson/gp_model_zoo
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
        
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="https://jejjohnson.github.io/gp_model_zoo" title="GP Model Zoo" class="md-nav__button md-logo" aria-label="GP Model Zoo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12,8A3,3 0 0,0 15,5A3,3 0 0,0 12,2A3,3 0 0,0 9,5A3,3 0 0,0 12,8M12,11.54C9.64,9.35 6.5,8 3,8V19C6.5,19 9.64,20.35 12,22.54C14.36,20.35 17.5,19 21,19V8C17.5,8 14.36,9.35 12,11.54Z" /></svg>

    </a>
    GP Model Zoo
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/jejjohnson/gp_model_zoo/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    jejjohnson/gp_model_zoo
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../.." title="Home" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../software/" title="Software" class="md-nav__link">
      Software
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../intro/" title="Intro to GPs" class="md-nav__link">
      Intro to GPs
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4">
    
    <label class="md-nav__link" for="nav-4">
      Literature
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59,16.58L13.17,12L8.59,7.41L10,6L16,12L10,18L8.59,16.58Z" /></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="Literature" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20,11V13H8L13.5,18.5L12.08,19.92L4.16,12L12.08,4.08L13.5,5.5L8,11H20Z" /></svg>
        </span>
        Literature
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../literature/" title="About" class="md-nav__link">
      About
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../literature/kernels/" title="Kernels" class="md-nav__link">
      Kernels
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../literature/sparse_gps/" title="Sparse GPs" class="md-nav__link">
      Sparse GPs
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../literature/inference/" title="Inference" class="md-nav__link">
      Inference
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../literature/deep_gps/" title="Deep GPs" class="md-nav__link">
      Deep GPs
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../literature/multioutput/" title="Multi-Output" class="md-nav__link">
      Multi-Output
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5">
    
    <label class="md-nav__link" for="nav-5">
      Demos
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59,16.58L13.17,12L8.59,7.41L10,6L16,12L10,18L8.59,16.58Z" /></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="Demos" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20,11V13H8L13.5,18.5L12.08,19.92L4.16,12L12.08,4.08L13.5,5.5L8,11H20Z" /></svg>
        </span>
        Demos
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../" title="Overview" class="md-nav__link">
      Overview
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../1d_example/" title="1D Example" class="md-nav__link">
      1D Example
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20,11V13H8L13.5,18.5L12.08,19.92L4.16,12L12.08,4.08L13.5,5.5L8,11H20Z" /></svg>
      </span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#background" class="md-nav__link">
    Background
  </a>
  
    <nav class="md-nav" aria-label="Background">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#method-1-sparse" class="md-nav__link">
    Method 1 - Sparse
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#method-2-black-box-matrix-matrix-bbmm" class="md-nav__link">
    Method 2 - Black-Box Matrix-Matrix (BBMM)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data" class="md-nav__link">
    Data
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gp-model" class="md-nav__link">
    GP Model
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-step" class="md-nav__link">
    Training Step
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#predictions" class="md-nav__link">
    Predictions
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#visualization" class="md-nav__link">
    Visualization
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/jejjohnson/gp_model_zoo/edit/master/docs/demos/1d_example_ls.md" title="Edit this page" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71,7.04C21.1,6.65 21.1,6 20.71,5.63L18.37,3.29C18,2.9 17.35,2.9 16.96,3.29L15.12,5.12L18.87,8.87M3,17.25V21H6.75L17.81,9.93L14.06,6.18L3,17.25Z" /></svg>
                  </a>
                
                
                  
                    


  


<a href="https://github.com/jejjohnson/gp_model_zoo/docs/demos/1d_example_ls.md" title="1d_example_ls.md" class="md-content__button md-icon">
  Source
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
</a>
                  
                
                
                <h1 id="large-scale-1d-example-walk-through">Large Scale 1D Example Walk-through<a class="headerlink" href="#large-scale-1d-example-walk-through" title="Permanent link">&para;</a></h1>
<div class="admonition info">
<p class="admonition-title">Colab Notebooks</p>
<p><center></p>
<table>
<thead>
<tr>
<th align="center">Name</th>
<th align="center">Colab Notebook</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">scikit-learn</td>
<td align="center"><a href="https://colab.research.google.com/drive/1vbDP0vtILN6-FLO_kHOyebSMHeOYR5Y1?usp=sharing"><img alt="Open in Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></td>
</tr>
<tr>
<td align="center">GPFlow</td>
<td align="center"><a href="https://colab.research.google.com/drive/1_ip2kWmp344GC76Dj7IX3vYfTZsz-S-S?usp=sharing"><img alt="Open in Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></td>
</tr>
<tr>
<td align="center">GPyTorch</td>
<td align="center"><a href="https://colab.research.google.com/drive/15o9-BWW98fP6corLWOew5a0sZq-_3Yvl?usp=sharing"><img alt="Open in Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></td>
</tr>
</tbody>
</table>
<p></center></p>
</div>
<p>This demo we will demonstrate how different algorithms compare when</p>
<hr />
<h2 id="background">Background<a class="headerlink" href="#background" title="Permanent link">&para;</a></h2>
<p>In exact GP estimation, we try to minimize the negative marginal log-likelihood term given by:</p>
<div>
<div class="MathJax_Preview">
\log \mathcal{N}(y | 0, K + \sigma^2I) =
- \frac{1}{2} y^\top\left(  K + \sigma^2I \right)^{-1}y 
- \frac{1}{2}\log \left| K + \sigma^2 \right| - \frac{n}{2}\log 2\pi
</div>
<script type="math/tex; mode=display">
\log \mathcal{N}(y | 0, K + \sigma^2I) =
- \frac{1}{2} y^\top\left(  K + \sigma^2I \right)^{-1}y 
- \frac{1}{2}\log \left| K + \sigma^2 \right| - \frac{n}{2}\log 2\pi
</script>
</div>
<p>So typically any <strong>exact</strong> GP estimation, there will be two expensive parts to this algorithm: <span><span class="MathJax_Preview">K^{-1}</span><script type="math/tex">K^{-1}</script></span> and <span><span class="MathJax_Preview">\log |K|</span><script type="math/tex">\log |K|</script></span> which has a computational cost of <span><span class="MathJax_Preview">\mathcal{O}(N^3)</span><script type="math/tex">\mathcal{O}(N^3)</script></span>. <strong>This is bad and very expensive</strong>. Unless you have Google Cloud Platform computational services, you will suffer on a graduate student's laptop. We're talking an upper limit of 10K points if you're willing to be patient.</p>
<h3 id="method-1-sparse">Method 1 - Sparse<a class="headerlink" href="#method-1-sparse" title="Permanent link">&para;</a></h3>
<p>One thing we can do is to reduce the amount of points that we invert. These representative points are known as <strong>inducing points</strong>. This results in the Nyström approximation which changes our likelihood term from  <span><span class="MathJax_Preview">\log p(y|X,\theta)</span><script type="math/tex">\log p(y|X,\theta)</script></span> to:</p>
<div>
<div class="MathJax_Preview">\log \mathcal{N}(y | 0, K + \sigma^2I) \approx \log \mathcal{N}(y | 0, \tilde{K} + \sigma^2I)</div>
<script type="math/tex; mode=display">\log \mathcal{N}(y | 0, K + \sigma^2I) \approx \log \mathcal{N}(y | 0, \tilde{K} + \sigma^2I)</script>
</div>
<p>Notice how we haven't actually changing our formulation because we still have to calculate the inverse of <span><span class="MathJax_Preview">\tilde{K}</span><script type="math/tex">\tilde{K}</script></span> which is <span><span class="MathJax_Preview">\mathbb{R}^{N \times N}</span><script type="math/tex">\mathbb{R}^{N \times N}</script></span>. Using the <a href="https://en.wikipedia.org/wiki/Woodbury_matrix_identity">Woodbury matrix identity</a> for the kernel approximation form (<a href="https://en.wikipedia.org/wiki/Sherman%E2%80%93Morrison_formula">Sherman-Morrison Formula</a>):</p>
<div>
<div class="MathJax_Preview">(\tilde{K} + \sigma^2 I)^{-1}=\sigma^{-2}I - \sigma^{-4}K_z(K_{zz}+\sigma^{-2}K_z^{\top}K_z)^{-1}K_z^{\top}</div>
<script type="math/tex; mode=display">(\tilde{K} + \sigma^2 I)^{-1}=\sigma^{-2}I - \sigma^{-4}K_z(K_{zz}+\sigma^{-2}K_z^{\top}K_z)^{-1}K_z^{\top}</script>
</div>
<p>Now the matrix that we need to invert is <span><span class="MathJax_Preview">(K_{zz}+\sigma^{-2}K_z^{\top}K_z)^{-1}</span><script type="math/tex">(K_{zz}+\sigma^{-2}K_z^{\top}K_z)^{-1}</script></span> which is <span><span class="MathJax_Preview">(M \times M)</span><script type="math/tex">(M \times M)</script></span> which is considerably smaller if <span><span class="MathJax_Preview">M &lt;&lt; N</span><script type="math/tex">M << N</script></span>. So the overall computational complexity reduces from <span><span class="MathJax_Preview">\mathcal{O}(N^3)</span><script type="math/tex">\mathcal{O}(N^3)</script></span> to <span><span class="MathJax_Preview">\mathcal{O}(MN^2)</span><script type="math/tex">\mathcal{O}(MN^2)</script></span> where <span><span class="MathJax_Preview">M&lt;&lt;N</span><script type="math/tex">M<<N</script></span> <span><span class="MathJax_Preview">\mathcal{O}(NM^2)</span><script type="math/tex">\mathcal{O}(NM^2)</script></span>.</p>
<h3 id="method-2-black-box-matrix-matrix-bbmm">Method 2 - Black-Box Matrix-Matrix (BBMM)<a class="headerlink" href="#method-2-black-box-matrix-matrix-bbmm" title="Permanent link">&para;</a></h3>
<p>This uses good ol' matrix multiplication strategies that you saw in your numerical methods class but perhaps never paid attention to. It uses a modified batched version of the conjugate gradients for the most expensive parts of the algorithm. It also uses preconditioning strategies to speed up the convergence. So remember, GPU acceleration is powerful <strong>because</strong> it's comprised of many cores that utilize matrix multiplication. So this is why this is much faster and it scales in the settings of GPUs. So the overall computational complexity reduces from <span><span class="MathJax_Preview">\mathcal{O}(N^3)</span><script type="math/tex">\mathcal{O}(N^3)</script></span> to <span><span class="MathJax_Preview">\mathcal{O}(N^2)</span><script type="math/tex">\mathcal{O}(N^2)</script></span>.</p>
<p>Below, let's see how these methods do in approximating a 1D dataset in terms of speed.</p>
<hr />
<h2 id="data">Data<a class="headerlink" href="#data" title="Permanent link">&para;</a></h2>
<p>Let's generate a more complex example which would definitely require more than 25 data points to capture. (OK, Maybe not 10K but enough)...</p>
<div>
<div class="MathJax_Preview">
f(x) = \sin(3\pi x) + \frac{1}{3}\sin(9\pi x) + \frac{1}{2} \sin(7 \pi x)
</div>
<script type="math/tex; mode=display">
f(x) = \sin(3\pi x) + \frac{1}{3}\sin(9\pi x) + \frac{1}{2} \sin(7 \pi x)
</script>
</div>
<details class="info"><summary>Code</summary><div class="highlight"><pre><span></span><code><span class="n">n_samples</span> <span class="o">=</span> <span class="mi">10_000</span>

<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="mi">3</span> <span class="o">*</span> <span class="mf">3.14</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.3</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="mi">9</span> <span class="o">*</span> <span class="mf">3.14</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="mi">7</span> <span class="o">*</span> <span class="mf">3.14</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">1.1</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
<span class="n">X_plot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span> <span class="mf">1.3</span><span class="p">,</span> <span class="mf">1.3</span><span class="p">,</span> <span class="mi">100</span><span class="p">)[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span>  <span class="n">f</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.2</span> <span class="o">*</span> <span class="n">rng</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">y</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
</code></pre></div>

</details>
<p><center>
<strong>10,000 Data Points!</strong>
<img alt="Placeholder" loading="lazy" src="../pics/1d_example_ls/1d_example_ls.png" />
</center></p>
<p><strong>Source</strong>: <a href="https://gpflow.readthedocs.io/en/develop/notebooks/advanced/gps_for_big_data.html">GPFlow - Big Data Tutorial</a></p>
<hr />
<h2 id="gp-model">GP Model<a class="headerlink" href="#gp-model" title="Permanent link">&para;</a></h2>
<p>For this example, we'll just show the 3 different methods using the standard <code>linear</code> mention function and the <code>RBF</code> kernel matrix.. The code will be <strong>very identical</strong>. The only major difference is that the sparse approximations need some inducing points (representative points).</p>
<details class="code"><summary>GPFlow (Exact)</summary><div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">gpflow.mean_functions</span> <span class="kn">import</span> <span class="n">Linear</span>
<span class="kn">from</span> <span class="nn">gpflow.kernels</span> <span class="kn">import</span> <span class="n">RBF</span>
<span class="kn">from</span> <span class="nn">gpflow.models</span> <span class="kn">import</span> <span class="n">GPR</span>

<span class="c1"># define the kernel</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">RBF</span><span class="p">()</span>

<span class="c1"># define mean function</span>
<span class="n">mean_f</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">()</span>

<span class="c1"># define GP Model</span>
<span class="n">gp_model</span> <span class="o">=</span> <span class="n">GPR</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span> <span class="n">mean_function</span><span class="o">=</span><span class="n">mean_f</span><span class="p">)</span>
</code></pre></div>

</details>
<details class="code"><summary>GPFlow (Sparse)</summary><p><strong>Kernel &amp; Mean Function</strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">gpflow.mean_functions</span> <span class="kn">import</span> <span class="n">Linear</span>
<span class="kn">from</span> <span class="nn">gpflow.kernels</span> <span class="kn">import</span> <span class="n">RBF</span>

<span class="c1"># define the kernel</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">RBF</span><span class="p">()</span>

<span class="c1"># define mean function</span>
<span class="n">mean_f</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">()</span>
</code></pre></div>

<p><strong>Inducing Points</strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>

<span class="n">n_inducing</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">123</span>

<span class="c1"># KMeans model</span>
<span class="n">kmeans_clf</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">n_inducing</span><span class="p">)</span>
<span class="n">kmeans_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># get cluster centers as inducing points</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">kmeans_clf</span><span class="o">.</span><span class="n">cluster_centers_</span>
</code></pre></div>

<p><center>
<img alt="Placeholder" loading="lazy" src="../pics/1d_example_ls/gpflow_fit_ls_z.png" />
</center></p>
<p><strong>GP Model</strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">gpflow.models</span> <span class="kn">import</span> <span class="n">SGPR</span>

<span class="c1"># define GP Model</span>
<span class="n">sgpr_model</span> <span class="o">=</span> <span class="n">SGPR</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span>
    <span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span>
    <span class="n">inducing_variable</span><span class="o">=</span><span class="n">Z</span><span class="p">,</span>
    <span class="n">mean_function</span><span class="o">=</span><span class="n">mean_f</span><span class="p">,</span> 
<span class="p">)</span>


<span class="c1"># get a nice summary</span>
<span class="n">print_summary</span><span class="p">(</span><span class="n">sgpr_model</span><span class="p">,</span> <span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code>╒══════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤════════════╕
│ name                     │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │ value      │
╞══════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪════════════╡
│ SGPR.mean_function.A     │ Parameter │ Identity         │         │ True        │ <span class="o">(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)</span>  │ float64 │ <span class="o">[[</span><span class="m">1</span>.<span class="o">]]</span>     │
├──────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼────────────┤
│ SGPR.mean_function.b     │ Parameter │ Identity         │         │ True        │ <span class="o">(</span><span class="m">1</span>,<span class="o">)</span>    │ float64 │ <span class="o">[</span><span class="m">0</span>.<span class="o">]</span>       │
├──────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼────────────┤
│ SGPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ <span class="o">()</span>      │ float64 │ <span class="m">1</span>.0        │
├──────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼────────────┤
│ SGPR.kernel.lengthscales │ Parameter │ Softplus         │         │ True        │ <span class="o">()</span>      │ float64 │ <span class="m">1</span>.0        │
├──────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼────────────┤
│ SGPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ <span class="o">()</span>      │ float64 │ <span class="m">1</span>.0        │
├──────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼────────────┤
│ SGPR.inducing_variable.Z │ Parameter │ Identity         │         │ True        │ <span class="o">(</span><span class="m">50</span>, <span class="m">1</span><span class="o">)</span> │ float64 │ <span class="o">[[</span><span class="m">0</span>.118... │
╘══════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧════════════╛
</code></pre></div>

<details class="tip"><summary>Numpy 2 Tensor</summary><p>Notice how I didn't do anything about changing from the <code>np.ndarray</code> to the <code>tf.tensor</code>? Well that's because GPFlow is awesome and does it for you. Little things like that make the coding experience so much better.</p>
</details>
</details>
<details class="code"><summary>GPyTorch (Exact BBMM)</summary><div class="admonition warning">
<p class="admonition-title">Numpy to Tensor</p>
<p>Unfortunately, this is one of those things where PyTorch becomes more involved to use. There is no automatic conversion from a <code>np.ndarray</code> to a <code>torch.Tensor</code>. So in your code bases, you need to ensure that you do this.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># convert to tensor</span>
<span class="n">X_tensor</span><span class="p">,</span> <span class="n">y_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
</code></pre></div>

</div>
<p><strong>Define GP Model</strong></p>
<p>Again, this is involved. You need to create the GP model exactly how one would think about doing it. You need a mean function, a kernel function, a likelihood and some data. We inherit the <code>gpytorch.models.ExactGP</code> class and we're good to go.</p>
<div class="highlight"><pre><span></span><code><span class="lineno" data-linenos=" 1 "></span><span class="c1"># We will use the simplest form of GP model, exact inference</span>
<span class="lineno" data-linenos=" 2 "></span><span class="k">class</span> <span class="nc">GPModel</span><span class="p">(</span><span class="n">gpytorch</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">ExactGP</span><span class="p">):</span>
<span class="lineno" data-linenos=" 3 "></span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">,</span> <span class="n">mean_module</span><span class="p">,</span> <span class="n">covar_module</span><span class="p">):</span>
<span class="lineno" data-linenos=" 4 "></span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">)</span>
<span class="lineno" data-linenos=" 5 "></span>        <span class="c1"># Constant Mean function</span>
<span class="lineno" data-linenos=" 6 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">mean_module</span> <span class="o">=</span> <span class="n">mean_module</span>
<span class="lineno" data-linenos=" 7 "></span>        <span class="c1"># RBF Kernel Function</span>
<span class="lineno" data-linenos=" 8 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">covar_module</span> <span class="o">=</span> <span class="n">covar_module</span>
<span class="lineno" data-linenos=" 9 "></span>
<span class="lineno" data-linenos="10 "></span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="lineno" data-linenos="11 "></span>        <span class="n">mean_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_module</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="lineno" data-linenos="12 "></span>        <span class="n">covar_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">covar_module</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="lineno" data-linenos="13 "></span>        <span class="k">return</span> <span class="n">gpytorch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">MultivariateNormal</span><span class="p">(</span><span class="n">mean_x</span><span class="p">,</span> <span class="n">covar_x</span><span class="p">)</span>
</code></pre></div>

<p><strong>Initialize GP model</strong></p>
<p>Now that we've defined our GP, we can intialize it with the appropriate parameters - <strong>mean function</strong>, <strong>kernel function</strong> and <strong>likelihood</strong>.</p>
<div class="highlight"><pre><span></span><code><span class="lineno" data-linenos=" 1 "></span><span class="c1"># initialize mean function</span>
<span class="lineno" data-linenos=" 2 "></span><span class="n">mean_f</span> <span class="o">=</span> <span class="n">gpytorch</span><span class="o">.</span><span class="n">means</span><span class="o">.</span><span class="n">ConstantMean</span><span class="p">()</span>
<span class="lineno" data-linenos=" 3 "></span>
<span class="lineno" data-linenos=" 4 "></span><span class="c1"># initialize kernel function</span>
<span class="lineno" data-linenos=" 5 "></span><span class="n">kernel</span> <span class="o">=</span> <span class="n">gpytorch</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">ScaleKernel</span><span class="p">(</span><span class="n">gpytorch</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">RBFKernel</span><span class="p">())</span>
<span class="lineno" data-linenos=" 6 "></span>
<span class="lineno" data-linenos=" 7 "></span><span class="c1"># intialize the likelihood</span>
<span class="lineno" data-linenos=" 8 "></span><span class="n">likelihood</span> <span class="o">=</span> <span class="n">gpytorch</span><span class="o">.</span><span class="n">likelihoods</span><span class="o">.</span><span class="n">GaussianLikelihood</span><span class="p">()</span>
<span class="lineno" data-linenos=" 9 "></span>
<span class="lineno" data-linenos="10 "></span><span class="c1"># initialize the gp model with the likelihood</span>
<span class="lineno" data-linenos="11 "></span><span class="n">gp_model</span> <span class="o">=</span> <span class="n">GPModel</span><span class="p">(</span><span class="n">X_tensor</span><span class="p">,</span> <span class="n">y_tensor</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">,</span> <span class="n">mean_f</span><span class="p">,</span> <span class="n">kernel</span><span class="p">)</span>
</code></pre></div>

<p>And we're done! So now you noticed that you learned a bit more than necessary to actually understand how the GP works because you had to build it from scratch (to some extent). This can be cumbersome but it might be more useful than the <code>sklearn</code> implementation because it gives us a bit more flexibility.</p>
<div class="admonition important">
<p class="admonition-title">GPU</p>
<p>So to get some scaling and faster training, we can use the GPU. For PyTorch, that means converting everything to a Tensor format.</p>
<div class="highlight"><pre><span></span><code><span class="n">X_tensor</span> <span class="o">=</span> <span class="n">X_tensor</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">y_tensor</span> <span class="o">=</span> <span class="n">y_tensor</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">gp_model</span> <span class="o">=</span> <span class="n">gp_model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">likelihood</span> <span class="o">=</span> <span class="n">likelihood</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
</code></pre></div>

</div>
</details>
<hr />
<h2 id="training-step">Training Step<a class="headerlink" href="#training-step" title="Permanent link">&para;</a></h2>
<div class="admonition tip">
<p class="admonition-title">Training Time</p>
<p><center></p>
<table>
<thead>
<tr>
<th align="center">GPFlow (Exact)</th>
<th align="center">GPFlow (Sparse)</th>
<th align="center">GPyTorch (Exact)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">24 minutes</td>
<td align="center"><strong>3 seconds</strong></td>
<td align="center"><strong>30 seconds</strong></td>
</tr>
<tr>
<td align="center">GPU</td>
<td align="center">GPU</td>
<td align="center">GPU</td>
</tr>
</tbody>
</table>
<p></center></p>
</div>
<details><summary>GPFlow (Exact)</summary><div class="highlight"><pre><span></span><code><span class="c1"># define optimizer and params</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Scipy</span><span class="p">()</span>
<span class="n">method</span> <span class="o">=</span> <span class="s2">&quot;L-BFGS-B&quot;</span>
<span class="n">n_iters</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1"># optimize</span>
<span class="n">opt_logs</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span>
    <span class="n">gp_model</span><span class="o">.</span><span class="n">training_loss</span><span class="p">,</span>
    <span class="n">gp_model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">,</span> 
    <span class="n">options</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">maxiter</span><span class="o">=</span><span class="n">n_iters</span><span class="p">),</span>
    <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># print a summary of the results</span>
<span class="n">print_summary</span><span class="p">(</span><span class="n">gp_model</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code>╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤═════════════════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │ value               │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪═════════════════════╡
│ GPR.mean_function.A     │ Parameter │ Identity         │         │ True        │ <span class="o">(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)</span>  │ float64 │ <span class="o">[[</span>-0.109<span class="o">]]</span>          │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────────────────┤
│ GPR.mean_function.b     │ Parameter │ Identity         │         │ True        │ <span class="o">(</span><span class="m">1</span>,<span class="o">)</span>    │ float64 │ <span class="o">[</span>-0.027<span class="o">]</span>            │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────────────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ <span class="o">()</span>      │ float64 │ <span class="m">1</span>.4583605690651238  │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────────────────┤
│ GPR.kernel.lengthscales │ Parameter │ Softplus         │         │ True        │ <span class="o">()</span>      │ float64 │ <span class="m">0</span>.10119699753609418 │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────────────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ <span class="o">()</span>      │ float64 │ <span class="m">0</span>.03981121449717302 │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧═════════════════════╛
CPU times: user 13min 42s, sys: 9min 57s, total: 23min 40s
Wall time: 24min 43s
</code></pre></div>

</details>
<details><summary>GPFlow (Sparse)</summary><div class="highlight"><pre><span></span><code><span class="c1"># define optimizer and params</span>
<span class="n">minibatch_size</span> <span class="o">=</span> <span class="mi">128</span>

<span class="c1"># turn of training for inducing points</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Scipy</span><span class="p">()</span>

<span class="c1"># training loss</span>
<span class="n">training_loss</span> <span class="o">=</span> <span class="n">sgpr_model</span><span class="o">.</span><span class="n">training_loss_closure</span><span class="p">()</span>
<span class="n">method</span> <span class="o">=</span> <span class="s2">&quot;L-BFGS-B&quot;</span>
<span class="n">n_iters</span> <span class="o">=</span> <span class="mi">1_000</span>

<span class="c1"># optimize</span>
<span class="n">opt_logs</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span>
    <span class="n">sgpr_model</span><span class="o">.</span><span class="n">training_loss</span><span class="p">,</span>
    <span class="n">sgpr_model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">,</span> 
    <span class="n">options</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">maxiter</span><span class="o">=</span><span class="n">n_iters</span><span class="p">),</span>
    <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># print a summary of the results</span>
<span class="n">print_summary</span><span class="p">(</span><span class="n">sgpr_model</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code>╒══════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤═════════════════════╕
│ name                     │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │ value               │
╞══════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪═════════════════════╡
│ SGPR.mean_function.A     │ Parameter │ Identity         │         │ True        │ <span class="o">(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)</span>  │ float64 │ <span class="o">[[</span>-0.111<span class="o">]]</span>          │
├──────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────────────────┤
│ SGPR.mean_function.b     │ Parameter │ Identity         │         │ True        │ <span class="o">(</span><span class="m">1</span>,<span class="o">)</span>    │ float64 │ <span class="o">[</span>-0.027<span class="o">]</span>            │
├──────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────────────────┤
│ SGPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ <span class="o">()</span>      │ float64 │ <span class="m">1</span>.4608235231409987  │
├──────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────────────────┤
│ SGPR.kernel.lengthscales │ Parameter │ Softplus         │         │ True        │ <span class="o">()</span>      │ float64 │ <span class="m">0</span>.10123051205205866 │
├──────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────────────────┤
│ SGPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ <span class="o">()</span>      │ float64 │ <span class="m">0</span>.03980796876613383 │
├──────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────────────────┤
│ SGPR.inducing_variable.Z │ Parameter │ Identity         │         │ True        │ <span class="o">(</span><span class="m">50</span>, <span class="m">1</span><span class="o">)</span> │ float64 │ <span class="o">[[</span><span class="m">0</span>.107...          │
╘══════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧═════════════════════╛
CPU times: user <span class="m">2</span>.01 s, sys: <span class="m">196</span> ms, total: <span class="m">2</span>.21 s
Wall time: <span class="m">2</span>.24 s══════════╧═════════╧═════════════╧═════════╧═════════╧═════════════════════╛
</code></pre></div>

</details>
<details><summary>GPyTorch (Exact BBMM)</summary><div class="admonition tip">
<p class="admonition-title">Same as small data</p>
<p>So this code is actually the same as the small data <a href="../1d_example/">1D Example</a>! We just have to change it to use the GPU and we're good to go!</p>
</div>
<p>So admittedly, this is where we start to enter into boilerplate code because this is stuff that needs to be done almost always.</p>
<p><strong>Set Model and Likelihood in Training Mode</strong></p>
<p>For this step, we need to let PyTorch know that we want all of the <code>layers</code> inside of our class primed and ready in train mode. </p>
<details class="info"><summary>Note</summary><p>This is mostly from things like BatchNormalization and DropOut which tend to behave differently between train and test. But we inherited the commands.</p>
</details>
<p><div class="highlight"><pre><span></span><code><span class="c1"># set model and likelihood in train mode</span>
<span class="n">likelihood</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="n">gp_model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</code></pre></div>
One nice thing is that it will give you a small overview of how the model looks as a tuple of tuples.</p>
<div class="highlight"><pre><span></span><code>GPModel<span class="o">(</span>
<span class="o">(</span>likelihood<span class="o">)</span>: GaussianLikelihood<span class="o">(</span>
    <span class="o">(</span>noise_covar<span class="o">)</span>: HomoskedasticNoise<span class="o">(</span>
    <span class="o">(</span>raw_noise_constraint<span class="o">)</span>: GreaterThan<span class="o">(</span><span class="m">1</span>.000E-04<span class="o">)</span>
    <span class="o">)</span>
<span class="o">)</span>
<span class="o">(</span>mean_module<span class="o">)</span>: ConstantMean<span class="o">()</span>
<span class="o">(</span>covar_module<span class="o">)</span>: ScaleKernel<span class="o">(</span>
    <span class="o">(</span>base_kernel<span class="o">)</span>: RBFKernel<span class="o">(</span>
    <span class="o">(</span>raw_lengthscale_constraint<span class="o">)</span>: Positive<span class="o">()</span>
    <span class="o">)</span>
    <span class="o">(</span>raw_outputscale_constraint<span class="o">)</span>: Positive<span class="o">()</span>
<span class="o">)</span>
<span class="o">)</span>
</code></pre></div>

<p><strong>Choose Optimizer and Loss</strong></p>
<p>Now we define the optimizer as well as the loss function.</p>
<div class="highlight"><pre><span></span><code><span class="lineno" data-linenos=" 1 "></span><span class="c1"># optimizer setup</span>
<span class="lineno" data-linenos=" 2 "></span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="lineno" data-linenos=" 3 "></span>
<span class="lineno" data-linenos=" 4 "></span><span class="c1"># Use the adam optimizer</span>
<span class="lineno" data-linenos=" 5 "></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span>
<span class="lineno" data-linenos=" 6 "></span>    <span class="n">gp_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span>
<span class="lineno" data-linenos=" 7 "></span><span class="p">)</span> 
<span class="lineno" data-linenos=" 8 "></span>
<span class="lineno" data-linenos=" 9 "></span><span class="c1"># Loss Function - the marginal log likelihood</span>
<span class="lineno" data-linenos="10 "></span><span class="n">mll</span> <span class="o">=</span> <span class="n">gpytorch</span><span class="o">.</span><span class="n">mlls</span><span class="o">.</span><span class="n">ExactMarginalLogLikelihood</span><span class="p">(</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">gp_model</span><span class="p">)</span>
</code></pre></div>

<p><strong>Training</strong></p>
<p>And now we can finally train our model! Now, all of this that comes after is boilerplate code. We have to do it almost every time when using PyTorch. No escaping unless you want to use another package (which you should; I'll demonstrate that in a later tutorial).</p>
<div class="highlight"><pre><span></span><code><span class="lineno" data-linenos=" 1 "></span><span class="c1"># choose iterations</span>
<span class="lineno" data-linenos=" 2 "></span><span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="lineno" data-linenos=" 3 "></span>
<span class="lineno" data-linenos=" 4 "></span><span class="c1"># initialize progressbar</span>
<span class="lineno" data-linenos=" 5 "></span><span class="k">with</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">notebook</span><span class="o">.</span><span class="n">trange</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">)</span> <span class="k">as</span> <span class="n">pbar</span><span class="p">:</span>
<span class="lineno" data-linenos=" 6 "></span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">:</span>
<span class="lineno" data-linenos=" 7 "></span>        <span class="c1"># Zero gradients from previous iteration</span>
<span class="lineno" data-linenos=" 8 "></span>        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="lineno" data-linenos=" 9 "></span>
<span class="lineno" data-linenos="10 "></span>        <span class="c1"># Output from model</span>
<span class="lineno" data-linenos="11 "></span>        <span class="n">output</span> <span class="o">=</span> <span class="n">gp_model</span><span class="p">(</span><span class="n">X_tensor</span><span class="p">)</span>
<span class="lineno" data-linenos="12 "></span>        <span class="c1"># Calc loss</span>
<span class="lineno" data-linenos="13 "></span>        <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">mll</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">y_tensor</span><span class="p">)</span>
<span class="lineno" data-linenos="14 "></span>
<span class="lineno" data-linenos="15 "></span>        <span class="c1"># backprop gradients</span>
<span class="lineno" data-linenos="16 "></span>        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="lineno" data-linenos="17 "></span>
<span class="lineno" data-linenos="18 "></span>        <span class="c1"># get parameters we want to track</span>
<span class="lineno" data-linenos="19 "></span>        <span class="n">postfix</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
<span class="lineno" data-linenos="20 "></span>            <span class="n">Loss</span><span class="o">=</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
<span class="lineno" data-linenos="21 "></span>            <span class="n">scale</span><span class="o">=</span><span class="n">gp_model</span><span class="o">.</span><span class="n">covar_module</span><span class="o">.</span><span class="n">outputscale</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
<span class="lineno" data-linenos="22 "></span>            <span class="n">length_scale</span><span class="o">=</span><span class="n">gp_model</span><span class="o">.</span><span class="n">covar_module</span><span class="o">.</span><span class="n">base_kernel</span><span class="o">.</span><span class="n">lengthscale</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
<span class="lineno" data-linenos="23 "></span>            <span class="n">noise</span><span class="o">=</span><span class="n">gp_model</span><span class="o">.</span><span class="n">likelihood</span><span class="o">.</span><span class="n">noise</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="lineno" data-linenos="24 "></span>            <span class="p">)</span>
<span class="lineno" data-linenos="25 "></span>
<span class="lineno" data-linenos="26 "></span>        <span class="c1"># step forward in the optimization</span>
<span class="lineno" data-linenos="27 "></span>        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="lineno" data-linenos="28 "></span>
<span class="lineno" data-linenos="29 "></span>        <span class="c1"># update the progress bar</span>
<span class="lineno" data-linenos="30 "></span>        <span class="n">pbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">postfix</span><span class="p">)</span>
</code></pre></div>

</details>
<hr />
<h2 id="predictions">Predictions<a class="headerlink" href="#predictions" title="Permanent link">&para;</a></h2>
<details class="code"><summary>GPFlow (Exact)</summary><div class="highlight"><pre><span></span><code><span class="c1"># generate some points for plotting</span>
<span class="n">X_plot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">100</span><span class="p">)[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>

<span class="c1"># predictive mean and standard deviation</span>
<span class="n">y_mean</span><span class="p">,</span> <span class="n">y_var</span> <span class="o">=</span> <span class="n">gp_model</span><span class="o">.</span><span class="n">predict_y</span><span class="p">(</span><span class="n">X_plot</span><span class="p">)</span>

<span class="c1"># convert to numpy arrays</span>
<span class="n">y_mean</span><span class="p">,</span> <span class="n">y_var</span> <span class="o">=</span> <span class="n">y_mean</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">y_var</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="c1"># confidence intervals</span>
<span class="n">y_upper</span> <span class="o">=</span> <span class="n">y_mean</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">y_var</span><span class="p">)</span>
<span class="n">y_lower</span> <span class="o">=</span> <span class="n">y_mean</span> <span class="o">-</span> <span class="mi">2</span><span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">y_var</span><span class="p">)</span>
</code></pre></div>

<details class="tip"><summary>Tensor 2 Numpy</summary><p>So we do have to convert to numpy arrays from tensors for the predictions. Note, you can plot tensors, but some of the commands might be different.</p>
<p>E.g. </p>
<div class="highlight"><pre><span></span><code><span class="n">y_upper</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">y_mean</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">y_var</span><span class="p">))</span>
</code></pre></div>

</details>
</details>
<details class="code"><summary>GPFlow (Sparse)</summary><div class="highlight"><pre><span></span><code><span class="c1"># generate some points for plotting</span>
<span class="n">X_plot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="mi">100</span><span class="p">)[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>

<span class="c1"># predictive mean and standard deviation</span>
<span class="n">y_mean</span><span class="p">,</span> <span class="n">y_var</span> <span class="o">=</span> <span class="n">sgpr_model</span><span class="o">.</span><span class="n">predict_y</span><span class="p">(</span><span class="n">X_plot</span><span class="p">)</span>


<span class="c1"># convert to numpy arrays</span>
<span class="n">y_mean</span><span class="p">,</span> <span class="n">y_var</span> <span class="o">=</span> <span class="n">y_mean</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">y_var</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="c1"># confidence intervals</span>
<span class="n">y_upper</span> <span class="o">=</span> <span class="n">y_mean</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">y_var</span><span class="p">)</span>
<span class="n">y_lower</span> <span class="o">=</span> <span class="n">y_mean</span> <span class="o">-</span> <span class="mi">2</span><span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">y_var</span><span class="p">)</span>

<span class="c1"># Get learned inducing points</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">sgpr_model</span><span class="o">.</span><span class="n">inducing_variable</span><span class="o">.</span><span class="n">Z</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</code></pre></div>

<details class="tip"><summary>Tensor 2 Numpy</summary><p>So we do have to convert to numpy arrays from tensors for the predictions. Note, you can plot tensors, but some of the commands might be different.</p>
<p>E.g. </p>
<div class="highlight"><pre><span></span><code><span class="n">y_upper</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">y_mean</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">y_var</span><span class="p">))</span>
</code></pre></div>

</details>
</details>
<details class="code"><summary>GPyTorch (Exact BBMM)</summary><div class="admonition tip">
<p class="admonition-title">Same as small data<p>Again, this code is actually the same as the small data <a href="../1d_example/">1D Example</a>! We just have to port our input data to the GPU (always)!</p>
</p>
</div>
<p>We're still now out of it yet. We still need to do a few extra stuff to get predictions. Here we can simply</p>
<p><strong>Eval Mode</strong></p>
<p>We need to put our model back in <code>.eval</code> mode. This will allow all layers to behave in eval mode.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># put the model in eval mode</span>
<span class="n">gp_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">likelihood</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</code></pre></div>

<p>One nice thing is that the resulting <code>observed_pred</code> is actually a class with a few methods and properties, e.g. <code>mean</code>, <code>variance</code>, <code>confidence_region</code>. Very convenient for predictions.</p>
<div class="highlight"><pre><span></span><code><span class="lineno" data-linenos=" 1 "></span><span class="c1"># generate some points for plotting</span>
<span class="lineno" data-linenos=" 2 "></span><span class="n">X_plot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">100</span><span class="p">)[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
<span class="lineno" data-linenos=" 3 "></span>
<span class="lineno" data-linenos=" 4 "></span><span class="c1"># convert to tensor</span>
<span class="lineno" data-linenos=" 5 "></span><span class="n">X_plot_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">X_plot</span><span class="p">)</span>
<span class="lineno" data-linenos=" 6 "></span>
<span class="lineno" data-linenos=" 7 "></span>
<span class="lineno" data-linenos=" 8 "></span><span class="c1"># turn off the gradient-tracking</span>
<span class="lineno" data-linenos=" 9 "></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="lineno" data-linenos="10 "></span>
<span class="lineno" data-linenos="11 "></span>    <span class="c1"># generate data</span>
<span class="lineno" data-linenos="12 "></span>    <span class="n">X_plot_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="lineno" data-linenos="13 "></span>
<span class="lineno" data-linenos="14 "></span>    <span class="c1"># convert tensor to CUDA</span>
<span class="lineno" data-linenos="15 "></span>    <span class="n">X_plot_tensor</span> <span class="o">=</span> <span class="n">X_plot_tensor</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="lineno" data-linenos="16 "></span>
<span class="lineno" data-linenos="17 "></span>    <span class="c1"># get predictions</span>
<span class="lineno" data-linenos="18 "></span>    <span class="n">observed_pred</span> <span class="o">=</span> <span class="n">likelihood</span><span class="p">(</span><span class="n">gp_model</span><span class="p">(</span><span class="n">X_plot_tensor</span><span class="p">))</span>
<span class="lineno" data-linenos="19 "></span>
<span class="lineno" data-linenos="20 "></span>    <span class="c1"># extract mean prediction</span>
<span class="lineno" data-linenos="21 "></span>    <span class="n">y_mean_tensor</span> <span class="o">=</span> <span class="n">observed_pred</span><span class="o">.</span><span class="n">mean</span>
<span class="lineno" data-linenos="22 "></span>
<span class="lineno" data-linenos="23 "></span>    <span class="c1"># extract confidence intervals</span>
<span class="lineno" data-linenos="24 "></span>    <span class="n">y_upper_tensor</span><span class="p">,</span> <span class="n">y_lower_tensor</span> <span class="o">=</span> <span class="n">observed_pred</span><span class="o">.</span><span class="n">confidence_region</span><span class="p">()</span>
</code></pre></div>

<p>And yes...we still have to convert our data to <code>np.ndarray</code>.
<div class="highlight"><pre><span></span><code><span class="c1"># convert to numpy array</span>
<span class="n">X_plot</span> <span class="o">=</span> <span class="n">X_plot_tensor</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">y_mean</span> <span class="o">=</span> <span class="n">y_mean_tensor</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">y_upper</span> <span class="o">=</span> <span class="n">y_upper_tensor</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">y_lower</span> <span class="o">=</span> <span class="n">y_lower_tensor</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</code></pre></div></p>
</details>
<hr />
<h2 id="visualization">Visualization<a class="headerlink" href="#visualization" title="Permanent link">&para;</a></h2>
<details class="info"><summary>Plot Function</summary><p>It's the same for all libraries as I first convert everything to numpy arrays and then plot the results.</p>
<div class="highlight"><pre><span></span><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> 
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training Data&quot;</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s1">&#39;Red&#39;</span><span class="p">,</span>
    <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span>
<span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">X_plot</span><span class="p">,</span> <span class="n">y_mean</span><span class="p">,</span> 
    <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Predictions&#39;</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span>
    <span class="n">X_plot</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> 
    <span class="n">y_upper</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> 
    <span class="n">y_lower</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> 
    <span class="n">color</span><span class="o">=</span><span class="s1">&#39;lightblue&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;95% Confidence&#39;</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">Z</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">Z</span><span class="p">),</span> 
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;|&quot;</span><span class="p">,</span> 
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Inducing locations&quot;</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>

</details>
<div class="tabbed-set" data-tabs="1:3"><input checked="checked" id="__tabbed_1_1" name="__tabbed_1" type="radio" /><label for="__tabbed_1_1">GPFlow (Exact)</label><div class="tabbed-content">
<p><center>
<img alt="Placeholder" src="../pics/1d_example_ls/gpflow_fit_ls_exact.png" />
</center></p>
</div>
<input id="__tabbed_1_2" name="__tabbed_1" type="radio" /><label for="__tabbed_1_2">GPFlow (Sparse)</label><div class="tabbed-content">
<p><center>
<img alt="Placeholder" src="../pics/1d_example_ls/gpflow_fit_ls.png" />
</center></p>
</div>
<input id="__tabbed_1_3" name="__tabbed_1" type="radio" /><label for="__tabbed_1_3">GPyTorch (Exact BBMM)</label><div class="tabbed-content">
<p><center>
<img alt="Placeholder" src="../pics/1d_example_ls/gpytorch_fit_ls.png" />
</center></p>
</div>
</div>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2020 J. Emmanuel Johnson
          </div>
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
  <div class="md-footer-social">
    
      
      
      <a href="https://github.com/jejjohnson" target="_blank" rel="noopener" title="github.com" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
      </a>
    
      
      
      <a href="https://twitter.com/jejjohnson" target="_blank" rel="noopener" title="twitter.com" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
      </a>
    
      
      
      <a href="https://linkedin.com/in/jejjohnson" target="_blank" rel="noopener" title="linkedin.com" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
      </a>
    
      
      
      <a href="https://jejjohnson.netlify.app" target="_blank" rel="noopener" title="jejjohnson.netlify.app" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path d="M336.5 160C322 70.7 287.8 8 248 8s-74 62.7-88.5 152h177zM152 256c0 22.2 1.2 43.5 3.3 64h185.3c2.1-20.5 3.3-41.8 3.3-64s-1.2-43.5-3.3-64H155.3c-2.1 20.5-3.3 41.8-3.3 64zm324.7-96c-28.6-67.9-86.5-120.4-158-141.6 24.4 33.8 41.2 84.7 50 141.6h108zM177.2 18.4C105.8 39.6 47.8 92.1 19.3 160h108c8.7-56.9 25.5-107.8 49.9-141.6zM487.4 192H372.7c2.1 21 3.3 42.5 3.3 64s-1.2 43-3.3 64h114.6c5.5-20.5 8.6-41.8 8.6-64s-3.1-43.5-8.5-64zM120 256c0-21.5 1.2-43 3.3-64H8.6C3.2 212.5 0 233.8 0 256s3.2 43.5 8.6 64h114.6c-2-21-3.2-42.5-3.2-64zm39.5 96c14.5 89.3 48.7 152 88.5 152s74-62.7 88.5-152h-177zm159.3 141.6c71.4-21.2 129.4-73.7 158-141.6h-108c-8.8 56.9-25.6 107.8-50 141.6zM19.3 352c28.6 67.9 86.5 120.4 158 141.6-24.4-33.8-41.2-84.7-50-141.6h-108z"/></svg>
      </a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/vendor.f81b9e8b.min.js"></script>
      <script src="../../assets/javascripts/bundle.23546af0.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents"}</script>
      
      <script>
        app = initialize({
          base: "../..",
          features: [],
          search: Object.assign({
            worker: "../../assets/javascripts/worker/search.58d22e8e.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
        <script src="../../javascripts/extra.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
      
    
  </body>
</html>